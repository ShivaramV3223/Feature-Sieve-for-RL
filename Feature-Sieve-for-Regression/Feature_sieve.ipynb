{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac563854-28fd-4d8b-8e5c-a7c719054939",
   "metadata": {},
   "source": [
    "# Feature Sieve\n",
    "## Dataset: CelebA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dc8d922-663a-4f9c-a940-bbe838430e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import copy\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b43db748-2eb6-48f3-99bd-ab2ea40875b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "GRAYSCALE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "675d3aac-1862-4b9d-87d2-b3d97e0d2a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>5_o_Clock_Shadow</th>\n",
       "      <th>Arched_Eyebrows</th>\n",
       "      <th>Attractive</th>\n",
       "      <th>Bags_Under_Eyes</th>\n",
       "      <th>Bald</th>\n",
       "      <th>Bangs</th>\n",
       "      <th>Big_Lips</th>\n",
       "      <th>Big_Nose</th>\n",
       "      <th>Black_Hair</th>\n",
       "      <th>...</th>\n",
       "      <th>Sideburns</th>\n",
       "      <th>Smiling</th>\n",
       "      <th>Straight_Hair</th>\n",
       "      <th>Wavy_Hair</th>\n",
       "      <th>Wearing_Earrings</th>\n",
       "      <th>Wearing_Hat</th>\n",
       "      <th>Wearing_Lipstick</th>\n",
       "      <th>Wearing_Necklace</th>\n",
       "      <th>Wearing_Necktie</th>\n",
       "      <th>Young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000003.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000004.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000005.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_id  5_o_Clock_Shadow  Arched_Eyebrows  Attractive  Bags_Under_Eyes  \\\n",
       "0  000001.jpg                 0                1           1                0   \n",
       "1  000002.jpg                 0                0           0                1   \n",
       "2  000003.jpg                 0                0           0                0   \n",
       "3  000004.jpg                 0                0           1                0   \n",
       "4  000005.jpg                 0                1           1                0   \n",
       "\n",
       "   Bald  Bangs  Big_Lips  Big_Nose  Black_Hair  ...  Sideburns  Smiling  \\\n",
       "0     0      0         0         0           0  ...          0        1   \n",
       "1     0      0         0         1           0  ...          0        1   \n",
       "2     0      0         1         0           0  ...          0        0   \n",
       "3     0      0         0         0           0  ...          0        0   \n",
       "4     0      0         1         0           0  ...          0        0   \n",
       "\n",
       "   Straight_Hair  Wavy_Hair  Wearing_Earrings  Wearing_Hat  Wearing_Lipstick  \\\n",
       "0              1          0                 1            0                 1   \n",
       "1              0          0                 0            0                 0   \n",
       "2              0          1                 0            0                 0   \n",
       "3              1          0                 1            0                 1   \n",
       "4              0          0                 0            0                 1   \n",
       "\n",
       "   Wearing_Necklace  Wearing_Necktie  Young  \n",
       "0                 0                0      1  \n",
       "1                 0                0      1  \n",
       "2                 0                0      1  \n",
       "3                 1                0      1  \n",
       "4                 0                0      1  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset\n",
    "DATA_DIR = \"./CelebA/img_align_celeba/img_align_celeba/\"\n",
    "CSV_DIR = \"./CelebA/list_attr_celeba.csv\"\n",
    "data = pd.read_csv(CSV_DIR)\n",
    "data.replace(-1, 0, inplace = True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86cfb636-3c26-4742-9acb-0910a20b790a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAHHCAYAAACiOWx7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABF9klEQVR4nO3deVwVhd7H8e8BZfeAK0uRC2pK7kuIpmmiqGjhcr0ut9TMzAuWejUjTUUrb1o3Lbe6lfSkltqepokYWkqWC26lqeGWAm6A4ILCPH/0cB5PgI4Igvl5v17nJWfmNzO/GY6H75ntWAzDMAQAAIBrcijtBgAAAG4HhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACYQmwIQaNWpo8ODBpd3Gbak0t92hQ4dksVgUExNTKsu3WCyaMmVKqSzbjIK2z+DBg+Xh4VF6TRXBP//5T3Xq1KnElxMTEyOLxaJDhw7d8LQltV379eunvn37Fvt8UTBCE8qUpKQkRUZGqm7dunJzc5Obm5sCAwMVERGhnTt3lnZ7kLRkyRLNmjWr1JY/ZcoUWSwW28PBwUG+vr7q3r27fvjhh1Lrqzj88ssvslgscnFxUVpaWr7x58+f15QpUxQfH59v3Ndff11mA1pJ9paUlKR33nlHzz//fL5xGRkZio6OVuPGjeXh4SFXV1c1aNBA48eP1/Hjx0ukn+KUlpYmFxcXWSwW/fLLLwXWjB8/Xp988ol27Nhxi7u7MxGaUGasWLFCDRo00AcffKCQkBC9/vrrmj17trp27aqvv/5aTZo00eHDh0u7zTvejYamffv26b///W+x9zF//nx98MEHiomJUWRkpHbv3q127dopMTGx2Jd1qyxatEg+Pj6SpI8//jjf+PPnzys6OrrQ0BQdHX1Dy6tevbouXLigRx99tEj9mlWU3syaPXu2atasqQ4dOtgN/+2339SkSRNNmzZNgYGBeuWVV/TGG2+oQ4cOevfdd9W+ffsS6ac4LV++XBaLRT4+Plq8eHGBNU2bNlWLFi302muv3eLu7kzlSrsBQJIOHjyofv36qXr16oqLi5Ovr6/d+FdeeUXz5s2Tg8Ptn/OvXLmi3NxcOTk5lXYrt4Szs3OJzLdPnz6qUqWK7Xl4eLgaNGig5cuXq0mTJiWyzJJkGIaWLFmiAQMGKCkpSYsXL9YTTzxRIsu6+jXo4uJSIsu4FS5fvqzFixfrqaeesht+5coV9erVSykpKYqPj9cDDzxgN/6ll17SK6+8citbLZJFixapW7duql69upYsWaIXX3yxwLq+fftq8uTJmjdv3m13aPV2c/v/BcJfwowZM5SVlaWFCxfmC0ySVK5cOT399NPy9/e3G75371716dNHlSpVkouLi1q0aKEvv/zSribvPISNGzdqzJgxqlq1qtzd3dWzZ0+dPHnSrtYwDL344ou6++675ebmpg4dOmjPnj0F9pyWlqZRo0bJ399fzs7Oql27tl555RXl5ubaavLOGXn11Vc1a9YsBQQEyNnZWT///PM1t8eiRYt0//33y83NTRUrVlS7du20Zs0au5p58+bpvvvuk7Ozs/z8/BQREZHvkE5h5xO1b9/e7pN2fHy8LBaLli1bppdeekl33323XFxc1LFjRx04cMBuupUrV+rw4cO2w2M1atS45rr8uYcb+X3ciLw9NOXKXf+z4Lp169S2bVu5u7vLy8tLjzzySL7DH3mHAQ8cOKDBgwfLy8tLnp6eGjJkiM6fP29Xe+nSJY0ePVpVq1ZVhQoV9PDDD+vYsWM31P/GjRt16NAh9evXT/369dOGDRvs5nHo0CFVrVpVkhQdHW3b/lOmTNHgwYM1d+5cSbI7dJk3XWGvwWud8/Xbb78pNDRU7u7u8vPz09SpU2UYhm183mvmz3u9/jzPa/UmSbm5uZo1a5buu+8+ubi4yNvbW8OHD9fZs2evu82+//57nTp1SiEhIXbD8w5XTZgwIV9gkiSr1aqXXnrJbtjmzZvVpUsXeXp6ys3NTQ8++KA2btx43R4kadWqVbbXU4UKFRQWFlbo+8b1tmueI0eO6LvvvrO9HpKSkrRp06YC59mpUydlZWUpNjbWVL8oOvY0oUxYsWKFateuraCgINPT7NmzR23atNFdd92l5557Tu7u7lq2bJnCw8P1ySefqGfPnnb1I0eOVMWKFTV58mQdOnRIs2bNUmRkpJYuXWqrmTRpkl588UV169ZN3bp107Zt29S5c2dlZ2fbzev8+fN68MEH9fvvv2v48OG65557tGnTJkVFRenEiRP5Dl8tXLhQFy9e1JNPPilnZ2dVqlSp0PWKjo7WlClT1Lp1a02dOlVOTk7avHmz1q1bp86dO0v64w96dHS0QkJCNGLECO3bt0/z58/XTz/9pI0bN6p8+fKmt+PV/v3vf8vBwUFjx45Venq6ZsyYoYEDB2rz5s2SpAkTJig9PV3Hjh3T66+/LklF/mRr5vdxLWfOnJH0xx/d33//XdOmTZOLi8t1T4pdu3atunbtqlq1amnKlCm6cOGC3nzzTbVp00bbtm3LFwL79u2rmjVravr06dq2bZveeecdVatWzW5PxRNPPKFFixZpwIABat26tdatW6ewsLAb2h6LFy9WQECAWrZsqQYNGsjNzU0ffvihxo0bJ0mqWrWq5s+frxEjRqhnz57q1auXJKlRo0bKysrS8ePHFRsbqw8++KDA+Rf0Grw64F8tJydHXbp0UatWrTRjxgytXr1akydP1pUrVzR16tQbWq/hw4dfs7fhw4crJiZGQ4YM0dNPP62kpCTNmTNH27dvv+5redOmTbJYLGratKnd8LwPTmYPO65bt05du3ZV8+bNNXnyZDk4OGjhwoV66KGH9N133+n+++8vdNoPPvhAgwYNUmhoqF555RWdP39e8+fP1wMPPKDt27fbvZ5uZLt++OGHcnd3V/fu3eXq6qqAgAAtXrxYrVu3ztdDYGCgXF1dtXHjxnzveyhmBlDK0tPTDUlGeHh4vnFnz541Tp48aXucP3/eNq5jx45Gw4YNjYsXL9qG5ebmGq1btzbq1KljG7Zw4UJDkhESEmLk5ubaho8ePdpwdHQ00tLSDMMwjNTUVMPJyckICwuzq3v++ecNScagQYNsw6ZNm2a4u7sbv/76q12/zz33nOHo6GgcOXLEMAzDSEpKMiQZVqvVSE1Nve622L9/v+Hg4GD07NnTyMnJsRuX11Nen507d7armTNnjiHJeO+992zDqlevbtd3ngcffNB48MEHbc+//fZbQ5JRv35949KlS7bhs2fPNiQZu3btsg0LCwszqlevft11KawHs7+PwkyePNmQlO/h5eVlrF692q42b/svXLjQNqxJkyZGtWrVjNOnT9uG7dixw3BwcDAee+yxfMt5/PHH7ebZs2dPo3LlyrbniYmJhiTjn//8p13dgAEDDEnG5MmTr7k+hmEY2dnZRuXKlY0JEybYTd+4cWO7upMnTxY6z4iICKOgt/RrvQYL2j6DBg0yJBkjR460DcvNzTXCwsIMJycn4+TJk4Zh/P9r5ttvv73uPAvr7bvvvjMkGYsXL7Ybvnr16gKH/9k//vEPu99FnqZNmxqenp7XnPbqdatTp44RGhpq93o8f/68UbNmTaNTp062YXmv3aSkJMMwDOPcuXOGl5eXMWzYMLt5JicnG56ennbDzW7XPA0bNjQGDhxoe/78888bVapUMS5fvlzgetStW9fo2rWrqXVG0XF4DqUuIyNDUsF7LNq3b6+qVavaHnm7+c+cOaN169apb9++OnfunE6dOqVTp07p9OnTCg0N1f79+/X777/bzevJJ5+0OyzQtm1b5eTk2E4uX7t2rbKzszVy5Ei7ulGjRuXra/ny5Wrbtq0qVqxoW3beYYKcnBxt2LDBrr537962QyvX8vnnnys3N1eTJk3Kd/5WXk95fY4aNcquZtiwYbJarVq5cuV1l1OYIUOG2J1r1bZtW0l/HFIobtf7fVzPJ598otjYWK1Zs0YLFy5U3bp11bt370IPYUjSiRMnlJiYqMGDB9vt7WvUqJE6deqkr7/+Ot80fz5fpm3btjp9+rTtdZs3zdNPP21XV9DrpjCrVq3S6dOn1b9/f9uw/v37a8eOHYUe5rlRZl+DeSIjI20/WywWRUZGKjs7W2vXri2WfqQ//h95enqqU6dOdv+PmjdvLg8PD3377bfXnP706dOqWLFivuEZGRmqUKGCqR4SExO1f/9+DRgwQKdPn7b1kJWVpY4dO2rDhg2F7pGLjY1VWlqa+vfvb9e/o6OjgoKCCuzfzHbduXOndu3ale/1cOrUKX3zzTcF9pL3XoSSxeE5lLq8N7fMzMx849566y2dO3dOKSkp+sc//mEbfuDAARmGoRdeeEEvvPBCgfNNTU3VXXfdZXt+zz332I3Pe7PNO3ci7491nTp17OqqVq2a7415//792rlzZ6F/hFJTU+2e16xZs8C6Pzt48KAcHBwUGBhYaE1en/fee6/dcCcnJ9WqVeumrjC83jYqTje7rHbt2tmdCN6nTx/VqVNHI0eO1NatWwucprBtJ0n169fXN998o6ysLLm7u5vq02q16vDhw3JwcFBAQIBdXUHLKMyiRYtUs2ZNOTs7284hCwgIkJubmxYvXqyXX37Z9LwKY/Y1KEkODg6qVauW3bC6detKUpHuUVSY/fv3Kz09XdWqVStw/J//HxXEKOB8IKvVajro79+/X5I0aNCgQmvS09MLDGd50z700EMFTme1Wu2em92uixYtkru7u2rVqmV7Pbi4uKhGjRpavHhxgYd+DcOw+xCCkkFoQqnz9PSUr6+vdu/enW9c3jlOf36jzvvkN3bsWIWGhhY439q1a9s9d3R0LLCuoDfd68nNzVWnTp307LPPFjg+740wj6ur6w0vozgU9iaak5NT4PYozm10PcW9LA8PDwUFBemLL77IF3xuRklvk4yMDH311Ve6ePFivsAu/XGLh5deeumm/yAW92vwWq8ts3Jzc1WtWrVCL6e/3p6xypUrFxiy69Wrp+3bt+vo0aP5Lh4pqAdJmjlzZqFXXRZ23l7etB988IHtQoSrmbko4c8Mw9CHH36orKysAj88paamKjMzM19PZ8+eLfD1g+JFaEKZEBYWpnfeeUc//vjjNU+6zJP3aa18+fL5rpwpqurVq0v649Pj1Z8GT548me+NOSAgQJmZmcW27Kvnm5ubq59//rnQN/C8Pvft22fXZ3Z2tpKSkux6qlixYoE3STx8+HC+T7xmleVPs1euXJH0x17LgkLT1dvuz/bu3asqVarccNiqXr26cnNzdfDgQbu9SwUtoyCffvqpLl68qPnz59vtOcubx8SJE7Vx40Y98MAD19z2xfl7yc3N1W+//WYX/n/99VdJsp3YnLfn5c+vr4L2dBbWW0BAgNauXas2bdoUKdTVq1dPixcvVnp6ujw9PW3De/TooQ8//FCLFi1SVFTUNeeRt4fQarXe8P/nvGmrVatmaloz23X9+vU6duyYpk6dqvr169tNf/bsWT355JP6/PPP7fa8X7lyRUePHtXDDz98Q/3jxnFOE8qEZ599Vm5ubnr88ceVkpKSb/yfP9VXq1ZN7du311tvvaUTJ07kqy/KpeshISEqX7683nzzTbvlFXQjx759+yohIaHA8wvS0tJsf7xvVHh4uBwcHDR16tR851Hk9RQSEiInJye98cYbdn2+++67Sk9Pt9t1HxAQoB9++MHu6r8VK1bo6NGjRepPktzd3ZWenl7k6UvKmTNntGnTJvn4+BR6uMfX11dNmjTR+++/b/fHfvfu3VqzZo26det2w8vt2rWrJOmNN96wG272BqCLFi1SrVq19NRTT6lPnz52j7Fjx8rDw8O2J8bNzU1S/qAiyRb2ChpXFHPmzLH9bBiG5syZo/Lly6tjx46S/giLjo6O+c7fmzdvnune+vbtq5ycHE2bNi3fNFeuXLnuugQHB8swjHyHY/v06aOGDRvqpZdeUkJCQr7pzp07pwkTJkiSmjdvroCAAL366qsFniJwrfeS0NBQWa1Wvfzyy7p8+bKpaa+3XfMOzY0bNy7f62HYsGGqU6dOvj1zP//8sy5evFjglXUoXuxpQplQp04dLVmyRP3799e9996rgQMHqnHjxjIMQ0lJSVqyZIkcHBx0991326aZO3euHnjgATVs2FDDhg1TrVq1lJKSooSEBB07duyGv1agatWqGjt2rKZPn67u3burW7du2r59u1atWpVvD8C4ceP05Zdfqnv37ho8eLCaN2+urKws7dq1Sx9//LEOHTqUbxozateurQkTJmjatGlq27atevXqJWdnZ/3000/y8/PT9OnTVbVqVUVFRSk6OlpdunTRww8/rH379mnevHlq2bKl3SfQJ554Qh9//LG6dOmivn376uDBg1q0aFG+829uRPPmzbV06VKNGTNGLVu2lIeHh3r06FHk+RXVxx9/LA8PDxmGoePHj+vdd9/V2bNntWDBgmvudZk5c6a6du2q4OBgDR061HbLAU9PzyJ91UeTJk3Uv39/zZs3T+np6WrdurXi4uLs7m9VmOPHj+vbb7/NdxJ5HmdnZ4WGhmr58uV644035OrqqsDAQC1dulR169ZVpUqV1KBBAzVo0EDNmzeX9McJ6aGhoXJ0dFS/fv1ueH2kP86fWb16tQYNGqSgoCCtWrVKK1eu1PPPP287ZObp6am//e1vevPNN2WxWBQQEKAVK1YUeB5SYb09+OCDGj58uKZPn67ExER17txZ5cuX1/79+7V8+XLNnj1bffr0KbTPBx54QJUrV9batWvtzisqX768Pv30U4WEhKhdu3bq27ev2rRpo/Lly2vPnj1asmSJKlasqJdeekkODg5655131LVrV913330aMmSI7rrrLv3+++/69ttvZbVa9dVXXxW4fKvVqvnz5+vRRx9Vs2bN1K9fP1WtWlVHjhzRypUr1aZNG7uQdL3teunSJX3yySfq1KlToTcdffjhhzV79mylpqbaPhzExsbKzc3tlnz/3h3vll+vB1zDgQMHjBEjRhi1a9c2XFxcDFdXV6NevXrGU089ZSQmJuarP3jwoPHYY48ZPj4+Rvny5Y277rrL6N69u/Hxxx/bavIuE/7pp5/spi3okumcnBwjOjra8PX1NVxdXY327dsbu3fvLvDS/XPnzhlRUVFG7dq1DScnJ6NKlSpG69atjVdffdXIzs42DOP/L7+eOXPmDW2H9957z2jatKnh7OxsVKxY0XjwwQeN2NhYu5o5c+YY9erVM8qXL294e3sbI0aMMM6ePZtvXq+99ppx1113Gc7OzkabNm2MLVu2FHrLgeXLl9tNW9Dl45mZmcaAAQMMLy8vQ9J1bz9Q2C0HzPw+ClLQLQfc3d2N4OBgY9myZdft3zAMY+3atUabNm0MV1dXw2q1Gj169DB+/vnnApfz50vB/3zZuWEYxoULF4ynn37aqFy5suHu7m706NHDOHr06HVvOfDaa68Zkoy4uLhCa2JiYgxJxhdffGEYhmFs2rTJaN68ueHk5GQ3/ytXrhgjR440qlatalgsFtsl/td6DRZ2ywF3d3fj4MGDRufOnQ03NzfD29vbmDx5cr7bYJw8edLo3bu34ebmZlSsWNEYPny4sXv37nzzLKy3PG+//bbRvHlzw9XV1ahQoYLRsGFD49lnnzWOHz9e6HbJ8/TTTxu1a9cucNzZs2eNSZMmGQ0bNjTc3NwMFxcXo0GDBkZUVJRx4sQJu9rt27cbvXr1MipXrmw4Ozsb1atXN/r27Wv3uynod28Yf7x2Q0NDDU9PT8PFxcUICAgwBg8ebGzZsuWGtusnn3xiSDLefffdQtc3Pj7ekGTMnj3bNiwoKMj4xz/+cd1thZtnMYwSOMMTAIBb4LffflO9evW0atUq2yGuO0liYqKaNWumbdu23ZZfH3S7ITQBAG5rI0aM0IEDB+7IrxHp16+fcnNztWzZstJu5Y5AaAIAADCBq+cAAABMIDQBAACYQGgCAAAwgdAEAABgAje3LCa5ubk6fvy4KlSoUKa/ZgIAAPw/wzB07tw5+fn5ycHh2vuSCE3F5Pjx49f9YkgAAFA2HT161O5bJwpCaComFSpUkPTHRrdaraXcDQAAMCMjI0P+/v62v+PXQmgqJnmH5KxWK6EJAIDbjJlTazgRHAAAwARCEwAAgAmEJgAAABMITQAAACYQmgAAAEwgNAEAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwoVxpNwAAgBnRFktpt4BSNtkwSnX57GkCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwARCEwAAgAmEJgAAABMITQAAACYQmgAAAEwgNAEAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwIRSDU3Tp09Xy5YtVaFCBVWrVk3h4eHat2+fXU379u1lsVjsHk899ZRdzZEjRxQWFiY3NzdVq1ZN48aN05UrV+xq4uPj1axZMzk7O6t27dqKiYnJ18/cuXNVo0YNubi4KCgoSD/++GOxrzMAALg9lWpoWr9+vSIiIvTDDz8oNjZWly9fVufOnZWVlWVXN2zYMJ04ccL2mDFjhm1cTk6OwsLClJ2drU2bNun9999XTEyMJk2aZKtJSkpSWFiYOnTooMTERI0aNUpPPPGEvvnmG1vN0qVLNWbMGE2ePFnbtm1T48aNFRoaqtTU1JLfEAAAoMyzGIZhlHYTeU6ePKlq1app/fr1ateunaQ/9jQ1adJEs2bNKnCaVatWqXv37jp+/Li8vb0lSQsWLND48eN18uRJOTk5afz48Vq5cqV2795tm65fv35KS0vT6tWrJUlBQUFq2bKl5syZI0nKzc2Vv7+/Ro4cqeeee+66vWdkZMjT01Pp6emyWq03sxkAAAWItlhKuwWUssklEFlu5O93mTqnKT09XZJUqVIlu+GLFy9WlSpV1KBBA0VFRen8+fO2cQkJCWrYsKEtMElSaGioMjIytGfPHltNSEiI3TxDQ0OVkJAgScrOztbWrVvtahwcHBQSEmKr+bNLly4pIyPD7gEAAP66ypV2A3lyc3M1atQotWnTRg0aNLANHzBggKpXry4/Pz/t3LlT48eP1759+/Tpp59KkpKTk+0CkyTb8+Tk5GvWZGRk6MKFCzp79qxycnIKrNm7d2+B/U6fPl3R0dE3t9IAAOC2UWZCU0REhHbv3q3vv//ebviTTz5p+7lhw4by9fVVx44ddfDgQQUEBNzqNm2ioqI0ZswY2/OMjAz5+/uXWj8AAKBklYnQFBkZqRUrVmjDhg26++67r1kbFBQkSTpw4IACAgLk4+OT7yq3lJQUSZKPj4/t37xhV9dYrVa5urrK0dFRjo6OBdbkzePPnJ2d5ezsbH4lAQDAba1Uz2kyDEORkZH67LPPtG7dOtWsWfO60yQmJkqSfH19JUnBwcHatWuX3VVusbGxslqtCgwMtNXExcXZzSc2NlbBwcGSJCcnJzVv3tyuJjc3V3FxcbYaAABwZyvVPU0RERFasmSJvvjiC1WoUMF2DpKnp6dcXV118OBBLVmyRN26dVPlypW1c+dOjR49Wu3atVOjRo0kSZ07d1ZgYKAeffRRzZgxQ8nJyZo4caIiIiJse4KeeuopzZkzR88++6wef/xxrVu3TsuWLdPKlSttvYwZM0aDBg1SixYtdP/992vWrFnKysrSkCFDbv2GAQAAZU6p3nLAUsjlowsXLtTgwYN19OhR/eMf/9Du3buVlZUlf39/9ezZUxMnTrS7LPDw4cMaMWKE4uPj5e7urkGDBunf//63ypX7/0wYHx+v0aNH6+eff9bdd9+tF154QYMHD7Zb7pw5czRz5kwlJyerSZMmeuONN2yHA6+HWw4AQMnilgMo7VsOlKn7NN3OCE0AULIITSjt0FSm7tMEAABQVhGaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwARCEwAAgAmEJgAAABMITQAAACYQmgAAAEwgNAEAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwARCEwAAgAmEJgAAABMITQAAACYQmgAAAEwgNAEAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmFCqoWn69Olq2bKlKlSooGrVqik8PFz79u2zq7l48aIiIiJUuXJleXh4qHfv3kpJSbGrOXLkiMLCwuTm5qZq1app3LhxunLlil1NfHy8mjVrJmdnZ9WuXVsxMTH5+pk7d65q1KghFxcXBQUF6ccffyz2dQYAALenUg1N69evV0REhH744QfFxsbq8uXL6ty5s7Kysmw1o0eP1ldffaXly5dr/fr1On78uHr16mUbn5OTo7CwMGVnZ2vTpk16//33FRMTo0mTJtlqkpKSFBYWpg4dOigxMVGjRo3SE088oW+++cZWs3TpUo0ZM0aTJ0/Wtm3b1LhxY4WGhio1NfXWbAwAAFCmWQzDMEq7iTwnT55UtWrVtH79erVr107p6emqWrWqlixZoj59+kiS9u7dq/r16yshIUGtWrXSqlWr1L17dx0/flze3t6SpAULFmj8+PE6efKknJycNH78eK1cuVK7d++2Latfv35KS0vT6tWrJUlBQUFq2bKl5syZI0nKzc2Vv7+/Ro4cqeeee+66vWdkZMjT01Pp6emyWq3FvWkA4I4XbbGUdgsoZZNLILLcyN/vMnVOU3p6uiSpUqVKkqStW7fq8uXLCgkJsdXUq1dP99xzjxISEiRJCQkJatiwoS0wSVJoaKgyMjK0Z88eW83V88iryZtHdna2tm7dalfj4OCgkJAQW82fXbp0SRkZGXYPAADw11VmQlNubq5GjRqlNm3aqEGDBpKk5ORkOTk5ycvLy67W29tbycnJtpqrA1Pe+Lxx16rJyMjQhQsXdOrUKeXk5BRYkzePP5s+fbo8PT1tD39//6KtOAAAuC2UmdAUERGh3bt366OPPirtVkyJiopSenq67XH06NHSbgkAAJSgcqXdgCRFRkZqxYoV2rBhg+6++27bcB8fH2VnZystLc1ub1NKSop8fHxsNX++yi3v6rqra/58xV1KSoqsVqtcXV3l6OgoR0fHAmvy5vFnzs7OcnZ2LtoKAwCA206p7mkyDEORkZH67LPPtG7dOtWsWdNufPPmzVW+fHnFxcXZhu3bt09HjhxRcHCwJCk4OFi7du2yu8otNjZWVqtVgYGBtpqr55FXkzcPJycnNW/e3K4mNzdXcXFxthoAAHBnK9U9TREREVqyZIm++OILVahQwXb+kKenp1xdXeXp6amhQ4dqzJgxqlSpkqxWq0aOHKng4GC1atVKktS5c2cFBgbq0Ucf1YwZM5ScnKyJEycqIiLCtifoqaee0pw5c/Tss8/q8ccf17p167Rs2TKtXLnS1suYMWM0aNAgtWjRQvfff79mzZqlrKwsDRky5NZvGAAAUOaUamiaP3++JKl9+/Z2wxcuXKjBgwdLkl5//XU5ODiod+/eunTpkkJDQzVv3jxbraOjo1asWKERI0YoODhY7u7uGjRokKZOnWqrqVmzplauXKnRo0dr9uzZuvvuu/XOO+8oNDTUVvP3v/9dJ0+e1KRJk5ScnKwmTZpo9erV+U4OBwAAd6YydZ+m2xn3aQKAksV9msB9mgAAAG4DhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwARCEwAAgAmEJgAAABMITQAAACYQmgAAAEwgNAEAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATChSaNq2bZt27dple/7FF18oPDxczz//vLKzs4utOQAAgLKiSKFp+PDh+vXXXyVJv/32m/r16yc3NzctX75czz77bLE2CAAAUBYUKTT9+uuvatKkiSRp+fLlateunZYsWaKYmBh98sknxdkfAABAmVCk0GQYhnJzcyVJa9euVbdu3SRJ/v7+OnXqVPF1BwAAUEYUKTS1aNFCL774oj744AOtX79eYWFhkqSkpCR5e3sXa4MAAABlQZFC0+uvv65t27YpMjJSEyZMUO3atSVJH3/8sVq3bl2sDQIAAJQF5YoyUePGje2unsszc+ZMlStXpFkCAACUaUXa01SrVi2dPn063/CLFy+qbt26N90UAABAWVOk0HTo0CHl5OTkG37p0iUdO3bsppsCAAAoa27oWNqXX35p+/mbb76Rp6en7XlOTo7i4uJUs2bN4usOAACgjLih0BQeHi5JslgsGjRokN248uXLq0aNGnrttdeKrTkAAICy4oZCU969mWrWrKmffvpJVapUKZGmAAAAypoiXeqWlJRU3H0AAACUaUW+P0BcXJzi4uKUmppq2wOV57333rvpxgAAAMqSIoWm6OhoTZ06VS1atJCvr68sFktx9wUAAFCmFOmWAwsWLFBMTIw2b96szz//XJ999pndw6wNGzaoR48e8vPzk8Vi0eeff243fvDgwbJYLHaPLl262NWcOXNGAwcOlNVqlZeXl4YOHarMzEy7mp07d6pt27ZycXGRv7+/ZsyYka+X5cuXq169enJxcVHDhg319ddfm98gAADgL69IoSk7O7tYvi4lKytLjRs31ty5cwut6dKli06cOGF7fPjhh3bjBw4cqD179ig2NlYrVqzQhg0b9OSTT9rGZ2RkqHPnzqpevbq2bt2qmTNnasqUKXr77bdtNZs2bVL//v01dOhQbd++XeHh4QoPD9fu3btveh0BAMBfg8UwDONGJxo/frw8PDz0wgsvFF8jFos+++wz220NpD/2NKWlpeXbA5Xnl19+UWBgoH766Se1aNFCkrR69Wp169ZNx44dk5+fn+bPn68JEyYoOTlZTk5OkqTnnntOn3/+ufbu3StJ+vvf/66srCytWLHCNu9WrVqpSZMmWrBggan+MzIy5OnpqfT0dFmt1iJsAQDAtURzKsgdb/KNR5brupG/30U6p+nixYt6++23tXbtWjVq1Ejly5e3G/+f//ynKLMtUHx8vKpVq6aKFSvqoYce0osvvqjKlStLkhISEuTl5WULTJIUEhIiBwcHbd68WT179lRCQoLatWtnC0ySFBoaqldeeUVnz55VxYoVlZCQoDFjxtgtNzQ0tNCwBgAA7jxFCk07d+5UkyZNJCnfIaziPCm8S5cu6tWrl2rWrKmDBw/q+eefV9euXZWQkCBHR0clJyerWrVqdtOUK1dOlSpVUnJysiQpOTk5313Kvb29beMqVqyo5ORk27Cra/LmUZBLly7p0qVLtucZGRk3ta4AAKBsK1Jo+vbbb4u7jwL169fP9nPDhg3VqFEjBQQEKD4+Xh07drwlPRRm+vTpio6OLtUeAADArVOkE8FLS61atVSlShUdOHBAkuTj46PU1FS7mitXrujMmTPy8fGx1aSkpNjV5D2/Xk3e+IJERUUpPT3d9jh69OjNrRwAACjTirSnqUOHDtc8DLdu3boiN3Qtx44d0+nTp+Xr6ytJCg4OVlpamrZu3armzZvblp2bm6ugoCBbzYQJE3T58mXbuVexsbG69957VbFiRVtNXFycRo0aZVtWbGysgoODC+3F2dlZzs7OJbGaAACgDCrSnqYmTZqocePGtkdgYKCys7O1bds2NWzY0PR8MjMzlZiYqMTEREl/fD1LYmKijhw5oszMTI0bN04//PCDDh06pLi4OD3yyCOqXbu2QkNDJUn169dXly5dNGzYMP3444/auHGjIiMj1a9fP/n5+UmSBgwYICcnJw0dOlR79uzR0qVLNXv2bLsTv5955hmtXr1ar732mvbu3aspU6Zoy5YtioyMLMrmAQAAf0FFuuVAYaZMmaLMzEy9+uqrpurj4+PVoUOHfMMHDRqk+fPnKzw8XNu3b1daWpr8/PzUuXNnTZs2ze6k7TNnzigyMlJfffWVHBwc1Lt3b73xxhvy8PCw1ezcuVMRERG2LxkeOXKkxo8fb7fM5cuXa+LEiTp06JDq1KmjGTNmqFu3bqbXnVsOAEDJ4pYDKO1bDhRraDpw4IDuv/9+nTlzprhmedsgNAFAySI0obRDU7GeCJ6QkCAXF5finCUAAECZUKQTwXv16mX33DAMnThxQlu2bCnWu4QDAACUFUUKTZ6ennbPHRwcdO+992rq1Knq3LlzsTQGAABQlhQpNC1cuLC4+wAAACjTihSa8mzdulW//PKLJOm+++5T06ZNi6UpAACAsqZIoSk1NVX9+vVTfHy8vLy8JElpaWnq0KGDPvroI1WtWrU4ewQAACh1Rbp6buTIkTp37pz27NmjM2fO6MyZM9q9e7cyMjL09NNPF3ePAAAApa5Ie5pWr16ttWvXqn79+rZhgYGBmjt3LieCAwCAv6Qi7WnKzc21fY/b1cqXL6/c3NybbgoAAKCsKVJoeuihh/TMM8/o+PHjtmG///67Ro8erY4dOxZbcwAAAGVFkULTnDlzlJGRoRo1aiggIEABAQGqWbOmMjIy9OabbxZ3jwAAAKWuSOc0+fv7a9u2bVq7dq327t0rSapfv75CQkKKtTkAAICy4ob2NK1bt06BgYHKyMiQxWJRp06dNHLkSI0cOVItW7bUfffdp++++66kegUAACg1NxSaZs2apWHDhhX4LcCenp4aPny4/vOf/xRbcwAAAGXFDYWmHTt2qEuXLoWO79y5s7Zu3XrTTQEAAJQ1NxSaUlJSCrzVQJ5y5crp5MmTN90UAABAWXNDoemuu+7S7t27Cx2/c+dO+fr63nRTAAAAZc0NhaZu3brphRde0MWLF/ONu3DhgiZPnqzu3bsXW3MAAABlhcUwDMNscUpKipo1ayZHR0dFRkbq3nvvlSTt3btXc+fOVU5OjrZt2yZvb+8Sa7isysjIkKenp9LT0ws8UR4AcHOiLZbSbgGlbLL5yGLajfz9vqH7NHl7e2vTpk0aMWKEoqKilJe3LBaLQkNDNXfu3DsyMAEAgL++G765ZfXq1fX111/r7NmzOnDggAzDUJ06dVSxYsWS6A8AAKBMKNIdwSWpYsWKatmyZXH2AgAAUGYV6bvnAAAA7jSEJgAAABMITQAAACYQmgAAAEwgNAEAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwARCEwAAgAmEJgAAABMITQAAACYQmgAAAEwgNAEAAJhAaAIAADChVEPThg0b1KNHD/n5+clisejzzz+3G28YhiZNmiRfX1+5uroqJCRE+/fvt6s5c+aMBg4cKKvVKi8vLw0dOlSZmZl2NTt37lTbtm3l4uIif39/zZgxI18vy5cvV7169eTi4qKGDRvq66+/Lvb1BQAAt69SDU1ZWVlq3Lix5s6dW+D4GTNm6I033tCCBQu0efNmubu7KzQ0VBcvXrTVDBw4UHv27FFsbKxWrFihDRs26Mknn7SNz8jIUOfOnVW9enVt3bpVM2fO1JQpU/T222/bajZt2qT+/ftr6NCh2r59u8LDwxUeHq7du3eX3MoDAIDbisUwDKO0m5Aki8Wizz77TOHh4ZL+2Mvk5+enf/3rXxo7dqwkKT09Xd7e3oqJiVG/fv30yy+/KDAwUD/99JNatGghSVq9erW6deumY8eOyc/PT/Pnz9eECROUnJwsJycnSdJzzz2nzz//XHv37pUk/f3vf1dWVpZWrFhh66dVq1Zq0qSJFixYYKr/jIwMeXp6Kj09XVartbg2CwDg/0RbLKXdAkrZ5BKILDfy97vMntOUlJSk5ORkhYSE2IZ5enoqKChICQkJkqSEhAR5eXnZApMkhYSEyMHBQZs3b7bVtGvXzhaYJCk0NFT79u3T2bNnbTVXLyevJm85Bbl06ZIyMjLsHgAA4K+rzIam5ORkSZK3t7fdcG9vb9u45ORkVatWzW58uXLlVKlSJbuaguZx9TIKq8kbX5Dp06fL09PT9vD397/RVQQAALeRMhuayrqoqCilp6fbHkePHi3tlgAAQAkqs6HJx8dHkpSSkmI3PCUlxTbOx8dHqampduOvXLmiM2fO2NUUNI+rl1FYTd74gjg7O8tqtdo9AADAX1eZDU01a9aUj4+P4uLibMMyMjK0efNmBQcHS5KCg4OVlpamrVu32mrWrVun3NxcBQUF2Wo2bNigy5cv22piY2N17733qmLFiraaq5eTV5O3HAAAgFINTZmZmUpMTFRiYqKkP07+TkxM1JEjR2SxWDRq1Ci9+OKL+vLLL7Vr1y499thj8vPzs11hV79+fXXp0kXDhg3Tjz/+qI0bNyoyMlL9+vWTn5+fJGnAgAFycnLS0KFDtWfPHi1dulSzZ8/WmDFjbH0888wzWr16tV577TXt3btXU6ZM0ZYtWxQZGXmrNwkAACijSvWWA/Hx8erQoUO+4YMGDVJMTIwMw9DkyZP19ttvKy0tTQ888IDmzZununXr2mrPnDmjyMhIffXVV3JwcFDv3r31xhtvyMPDw1azc+dORURE6KefflKVKlU0cuRIjR8/3m6Zy5cv18SJE3Xo0CHVqVNHM2bMULdu3UyvC7ccAICSxS0HUNq3HCgz92m63RGaAKBkEZpQ2qGpzJ7TBAAAUJYQmgAAAEwgNAEAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwARCEwAAgAmEJgAAABMITQAAACYQmgAAAEwgNAEAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwARCEwAAgAmEJgAAABMITQAAACYQmgAAAEwgNAEAAJhQpkPTlClTZLFY7B716tWzjb948aIiIiJUuXJleXh4qHfv3kpJSbGbx5EjRxQWFiY3NzdVq1ZN48aN05UrV+xq4uPj1axZMzk7O6t27dqKiYm5FasHAABuI2U6NEnSfffdpxMnTtge33//vW3c6NGj9dVXX2n58uVav369jh8/rl69etnG5+TkKCwsTNnZ2dq0aZPef/99xcTEaNKkSbaapKQkhYWFqUOHDkpMTNSoUaP0xBNP6Jtvvrml6wkAAMq2cqXdwPWUK1dOPj4++Yanp6fr3Xff1ZIlS/TQQw9JkhYuXKj69evrhx9+UKtWrbRmzRr9/PPPWrt2rby9vdWkSRNNmzZN48eP15QpU+Tk5KQFCxaoZs2aeu211yRJ9evX1/fff6/XX39doaGht3RdAQBA2VXm9zTt379ffn5+qlWrlgYOHKgjR45IkrZu3arLly8rJCTEVluvXj3dc889SkhIkCQlJCSoYcOG8vb2ttWEhoYqIyNDe/bssdVcPY+8mrx5FObSpUvKyMiwewAAgL+uMh2agoKCFBMTo9WrV2v+/PlKSkpS27Ztde7cOSUnJ8vJyUleXl5203h7eys5OVmSlJycbBeY8sbnjbtWTUZGhi5cuFBob9OnT5enp6ft4e/vf7OrCwAAyrAyfXiua9eutp8bNWqkoKAgVa9eXcuWLZOrq2spdiZFRUVpzJgxtucZGRkEJwAA/sLK9J6mP/Py8lLdunV14MAB+fj4KDs7W2lpaXY1KSkptnOgfHx88l1Nl/f8ejVWq/WawczZ2VlWq9XuAQAA/rpuq9CUmZmpgwcPytfXV82bN1f58uUVFxdnG79v3z4dOXJEwcHBkqTg4GDt2rVLqamptprY2FhZrVYFBgbaaq6eR15N3jwAAACkMh6axo4dq/Xr1+vQoUPatGmTevbsKUdHR/Xv31+enp4aOnSoxowZo2+//VZbt27VkCFDFBwcrFatWkmSOnfurMDAQD366KPasWOHvvnmG02cOFERERFydnaWJD311FP67bff9Oyzz2rv3r2aN2+eli1bptGjR5fmqgMAgDKmTJ/TdOzYMfXv31+nT59W1apV9cADD+iHH35Q1apVJUmvv/66HBwc1Lt3b126dEmhoaGaN2+ebXpHR0etWLFCI0aMUHBwsNzd3TVo0CBNnTrVVlOzZk2tXLlSo0eP1uzZs3X33XfrnXfe4XYDAADAjsUwDKO0m/gryMjIkKenp9LT0zm/CQBKQLTFUtotoJRNLoHIciN/v8v04TkAAICygtAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwARCEwAAgAmEJgAAABMITQAAACYQmgAAAEwgNAEAAJhAaAIAADCB0AQAAGACoQkAAMAEQhMAAIAJhCYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYEK50m4A5kRbLKXdAkrZZMMo7RYA4I7GniYAAAATCE0AAAAmEJoAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYAKhCQAAwARCEwAAgAmEpj+ZO3euatSoIRcXFwUFBenHH38s7ZYAAEAZQGi6ytKlSzVmzBhNnjxZ27ZtU+PGjRUaGqrU1NTSbg0AAJQyQtNV/vOf/2jYsGEaMmSIAgMDtWDBArm5uem9994r7dYAAEApIzT9n+zsbG3dulUhISG2YQ4ODgoJCVFCQkIpdgYAAMqCcqXdQFlx6tQp5eTkyNvb2264t7e39u7dm6/+0qVLunTpku15enq6JCkjI6NE+rtYInPF7aSkXlvA7YL3QZTE+2DePA3DuG4toamIpk+frujo6HzD/f39S6Eb3An+7elZ2i0AQKkqyffBc+fOyfM68yc0/Z8qVarI0dFRKSkpdsNTUlLk4+OTrz4qKkpjxoyxPc/NzdWZM2dUuXJlWSyWEu/3TpKRkSF/f38dPXpUVqu1tNsBgFuO98GSYxiGzp07Jz8/v+vWEpr+j5OTk5o3b664uDiFh4dL+iMIxcXFKTIyMl+9s7OznJ2d7YZ5eXndgk7vXFarlTcLAHc03gdLxvX2MOUhNF1lzJgxGjRokFq0aKH7779fs2bNUlZWloYMGVLarQEAgFJGaLrK3//+d508eVKTJk1ScnKymjRpotWrV+c7ORwAANx5CE1/EhkZWeDhOJQeZ2dnTZ48Od/hUAC4U/A+WDZYDDPX2AEAANzhuLklAACACYQmAAAAEwhNAAAAJhCacFs6dOiQLBaLEhMTS7sVACizatSooVmzZpV2G38ZhCbcMoMHD5bFYtFTTz2Vb1xERIQsFosGDx586xsDgGKQ9x7358eBAwdKuzUUE0ITbil/f3999NFHunDhgm3YxYsXtWTJEt1zzz2l2BkA3LwuXbroxIkTdo+aNWuWdlsoJoQm3FLNmjWTv7+/Pv30U9uwTz/9VPfcc4+aNm1qG7Z69Wo98MAD8vLyUuXKldW9e3cdPHjwmvPevXu3unbtKg8PD3l7e+vRRx/VqVOnSmxdAODPnJ2d5ePjY/dwdHTUF198oWbNmsnFxUW1atVSdHS0rly5YpvOYrHorbfeUvfu3eXm5qb69esrISFBBw4cUPv27eXu7q7WrVvbvQ8ePHhQjzzyiLy9veXh4aGWLVtq7dq11+wvLS1NTzzxhKpWrSqr1aqHHnpIO3bsKLHt8VdDaMIt9/jjj2vhwoW25++9916+r6rJysrSmDFjtGXLFsXFxcnBwUE9e/ZUbm5ugfNMS0vTQw89pKZNm2rLli1avXq1UlJS1Ldv3xJdFwC4nu+++06PPfaYnnnmGf3888966623FBMTo5deesmubtq0aXrssceUmJioevXqacCAARo+fLiioqK0ZcsWGYZhd/PlzMxMdevWTXFxcdq+fbu6dOmiHj166MiRI4X28re//U2pqalatWqVtm7dqmbNmqljx446c+ZMia3/X4oB3CKDBg0yHnnkESM1NdVwdnY2Dh06ZBw6dMhwcXExTp48aTzyyCPGoEGDCpz25MmThiRj165dhmEYRlJSkiHJ2L59u2EYhjFt2jSjc+fOdtMcPXrUkGTs27evJFcLAAzD+OM9ztHR0XB3d7c9+vTpY3Ts2NF4+eWX7Wo/+OADw9fX1/ZckjFx4kTb84SEBEOS8e6779qGffjhh4aLi8s1e7jvvvuMN9980/a8evXqxuuvv24YhmF89913htVqNS5evGg3TUBAgPHWW2/d8PreifgaFdxyVatWVVhYmGJiYmQYhsLCwlSlShW7mv3792vSpEnavHmzTp06ZdvDdOTIETVo0CDfPHfs2KFvv/1WHh4e+cYdPHhQdevWLZmVAYCrdOjQQfPnz7c9d3d3V6NGjbRx40a7PUs5OTm6ePGizp8/Lzc3N0lSo0aNbOPzvvO0YcOGdsMuXryojIwMWa1WZWZmasqUKVq5cqVOnDihK1eu6MKFC4XuadqxY4cyMzNVuXJlu+EXLly47ukP+AOhCaXi8ccft+1mnjt3br7xPXr0UPXq1fXf//5Xfn5+ys3NVYMGDZSdnV3g/DIzM9WjRw+98sor+cb5+voWb/MAUAh3d3fVrl3bblhmZqaio6PVq1evfPUuLi62n8uXL2/72WKxFDos70Pk2LFjFRsbq1dffVW1a9eWq6ur+vTpc833SV9fX8XHx+cb5+XlZW4F73CEJpSKLl26KDs7WxaLRaGhoXbjTp8+rX379um///2v2rZtK0n6/vvvrzm/Zs2a6ZNPPlGNGjVUrhwvawBlR7NmzbRv3758Yepmbdy4UYMHD1bPnj0l/RGKDh06dM0+kpOTVa5cOdWoUaNYe7lTcCI4SoWjo6N++eUX/fzzz3J0dLQbV7FiRVWuXFlvv/22Dhw4oHXr1mnMmDHXnF9ERITOnDmj/v3766efftLBgwf1zTffaMiQIcrJySnJVQGAa5o0aZL+53/+R9HR0dqzZ49++eUXffTRR5o4ceJNzbdOnTr69NNPlZiYqB07dmjAgAGFXiwjSSEhIQoODlZ4eLjWrFmjQ4cOadOmTZowYYK2bNlyU73cKQhNKDVWq1VWqzXfcAcHB3300UfaunWrGjRooNGjR2vmzJnXnJefn582btyonJwcde7cWQ0bNtSoUaPk5eUlBwde5gBKT2hoqFasWKE1a9aoZcuWatWqlV5//XVVr179pub7n//8RxUrVlTr1q3Vo0cPhYaGqlmzZoXWWywWff3112rXrp2GDBmiunXrql+/fjp8+LDtHCpcm8UwDKO0mwAAACjr+AgOAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAoAiat++vUaNGlXabQC4RQhNAG5rycnJeuaZZ1S7dm25uLjI29tbbdq00fz583X+/PnSbg/AXwjfbArgtvXbb7+pTZs28vLy0ssvv6yGDRvK2dlZu3bt0ttvv6277rpLDz/8cGm3WaicnBxZLBa+6ge4TfA/FcBt65///KfKlSunLVu2qG/fvqpfv75q1aqlRx55RCtXrlSPHj0kSWlpaXriiSdUtWpVWa1WPfTQQ9qxY4dtPlOmTFGTJk30wQcfqEaNGvL09FS/fv107tw5W01WVpYee+wxeXh4yNfXV6+99lq+fi5duqSxY8fqrrvukru7u4KCghQfH28bHxMTIy8vL3355ZcKDAyUs7Ozjhw5ovj4eN1///1yd3eXl5eX2rRpo8OHD5fchgNQJIQmALel06dPa82aNYqIiJC7u3uBNRaLRZL0t7/9TampqVq1apW2bt2qZs2aqWPHjjpz5oyt9uDBg/r888+1YsUKrVixQuvXr9e///1v2/hx48Zp/fr1+uKLL7RmzRrFx8dr27ZtdsuLjIxUQkKCPvroI+3cuVN/+9vf1KVLF+3fv99Wc/78eb3yyit65513tGfPHlWqVEnh4eF68MEHtXPnTiUkJOjJJ5+09Q6gDDEA4Db0ww8/GJKMTz/91G545cqVDXd3d8Pd3d149tlnje+++86wWq3GxYsX7eoCAgKMt956yzAMw5g8ebLh5uZmZGRk2MaPGzfOCAoKMgzDMM6dO2c4OTkZy5Yts40/ffq04erqajzzzDOGYRjG4cOHDUdHR+P333+3W07Hjh2NqKgowzAMY+HChYYkIzEx0W4+koz4+Pib3CIAShrnNAH4S/nxxx+Vm5urgQMH6tKlS9qxY4cyMzNVuXJlu7oLFy7o4MGDtuc1atRQhQoVbM99fX2Vmpoq6Y+9UNnZ2QoKCrKNr1Spku69917b8127diknJ0d169a1W86lS5fslu3k5KRGjRrZzWfw4MEKDQ1Vp06dFBISor59+8rX1/cmtwSA4kZoAnBbql27tiwWi/bt22c3vFatWpIkV1dXSVJmZqZ8fX3tzi3K4+XlZfu5fPnyduMsFotyc3NN95OZmSlHR0dt3bpVjo6OduM8PDxsP7u6uuY79LZw4UI9/fTTWr16tZYuXaqJEycqNjZWrVq1Mr18ACWPc5oA3JYqV66sTp06ac6cOcrKyiq0rlmzZkpOTla5cuVUu3Ztu0eVKlVMLSsgIEDly5fX5s2bbcPOnj2rX3/91fa8adOmysnJUWpqar7l+Pj4XHcZTZs2VVRUlDZt2qQGDRpoyZIlpnoDcOsQmgDctubNm6crV66oRYsWWrp0qX755Rft27dPixYt0t69e+Xo6KiQkBAFBwcrPDxca9as0aFDh7Rp0yZNmDBBW7ZsMbUcDw8PDR06VOPGjdO6deu0e/duDR482O5WAXXr1tXAgQP12GOP6dNPP1VSUpJ+/PFHTZ8+XStXrix03klJSYqKilJCQoIOHz6sNWvWaP/+/apfv/5Nbx8AxYvDcwBuWwEBAdq+fbtefvllRUVF6dixY3J2dlZgYKDGjh2rf/7zn7JYLPr66681YcIEDRkyRCdPnpSPj4/atWsnb29v08uaOXOmMjMz1aNHD1WoUEH/+te/lJ6eblezcOFCvfjii/rXv/6l33//XVWqVFGrVq3UvXv3Qufr5uamvXv36v3339fp06fl6+uriIgIDR8+vMjbBUDJsBiGYZR2EwAAAGUdh+cAAABMIDQBAACYQGgCAAAwgdAEAABgAqEJAADABEITAACACYQmAAAAEwhNAAAAJhCaAAAATCA0AQAAmEBoAgAAMIHQBAAAYML/AuBlYsh9KqI9AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = data.loc[:, ['Blond_Hair', \"Male\"]]\n",
    "blond = t[t['Blond_Hair'] == 1]\n",
    "male_blond = blond[blond['Male'] == 1]\n",
    "female_blond = blond[blond['Male'] == 0]\n",
    "\n",
    "gender = ['Male', \"Female\"]\n",
    "counts = [male_blond.shape[0], female_blond.shape[0]]\n",
    " \n",
    "# creating the bar plot\n",
    "plt.bar(gender, counts, color ='maroon', \n",
    "        width = 0.4)\n",
    " \n",
    "plt.xlabel(\"Genders\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.title(\"Gender count in Blond Attribute (CelebA)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3d5ddb6-f4f3-4314-b9a7-83d22f339345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset\n",
    "custom_transform = transforms.Compose([transforms.Resize((128, 128)),\n",
    "                                       transforms.RandomCrop((120, 120)),\n",
    "                                       transforms.ToTensor()])\n",
    "\n",
    "class CelebADataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, attr = \"Blond_Hair\", transform = None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "        self.image_dir = img_dir\n",
    "        self.images = dataframe[\"image_id\"].values\n",
    "        self.y = dataframe[attr]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.image_dir + self.images[index])\n",
    "\n",
    "        if self.transform is not None:\n",
    "          img = self.transform(img)\n",
    "    \n",
    "        label = self.y[index]\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc3e1264-c3ce-4713-919c-13da9b982da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Training Datapoints: 121559\n",
      "# of Validation Datapoints: 40519\n",
      "# of Test Datapoints: 40519\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATAPTS = int(0.6 * len(data))\n",
    "VAL_DATAPTS = int(0.2 * len(data))\n",
    "TEST_DATAPTS = int(0.2 * len(data))\n",
    "\n",
    "print(f\"# of Training Datapoints: {TRAIN_DATAPTS}\")\n",
    "print(f\"# of Validation Datapoints: {VAL_DATAPTS}\")\n",
    "print(f\"# of Test Datapoints: {TEST_DATAPTS}\")\n",
    "\n",
    "data = data.sample(frac = 1).reset_index(drop = True)\n",
    "\n",
    "train_df = data[:TRAIN_DATAPTS].reset_index(drop = True)\n",
    "val_df = data[TRAIN_DATAPTS: TRAIN_DATAPTS + VAL_DATAPTS].reset_index(drop = True)\n",
    "test_df = data[TRAIN_DATAPTS + VAL_DATAPTS: ].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed7e736e-dcdb-42b5-9ef2-cd2cf877b204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male Datapoints: 16925\n",
      "Female Datapoints :23596\n",
      "Male Blond: 374\n",
      "FeMale Blond: 5643\n",
      "Male Non Blond: 16551\n",
      "FeMale Non Blond: 17953\n"
     ]
    }
   ],
   "source": [
    "# Different groups\n",
    "male_df = test_df[test_df['Male'] == 1].reset_index(drop = True)\n",
    "female_df = test_df[test_df['Male'] == 0].reset_index(drop = True)\n",
    "\n",
    "print(f\"Male Datapoints: {male_df.shape[0]}\")\n",
    "print(f\"Female Datapoints :{female_df.shape[0]}\")\n",
    "\n",
    "## Hair color and Gender\n",
    "male_blond_df = male_df[male_df[\"Blond_Hair\"] == 1].reset_index(drop = True)\n",
    "female_blond_df = female_df[female_df[\"Blond_Hair\"] == 1].reset_index(drop = True)\n",
    "male_non_blond_df = male_df[male_df['Blond_Hair'] == 0].reset_index(drop = True)\n",
    "female_non_blond_df = female_df[female_df['Blond_Hair'] == 0].reset_index(drop = True)\n",
    "\n",
    "print(f\"Male Blond: {male_blond_df.shape[0]}\")\n",
    "print(f\"FeMale Blond: {female_blond_df.shape[0]}\")\n",
    "print(f\"Male Non Blond: {male_non_blond_df.shape[0]}\")\n",
    "print(f\"FeMale Non Blond: {female_non_blond_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5da8f9d-15b8-42c1-a0cc-51420074ed1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Dataset\n",
    "train_dataset = CelebADataset(dataframe  = train_df,\n",
    "                             img_dir = DATA_DIR,\n",
    "                             transform = custom_transform)\n",
    "\n",
    "train_dataloader = DataLoader(dataset = train_dataset,\n",
    "                             shuffle = True,\n",
    "                             batch_size = 128)\n",
    "# Validation Dataset\n",
    "val_dataset = CelebADataset(dataframe = val_df,\n",
    "                           img_dir = DATA_DIR,\n",
    "                           transform = custom_transform)\n",
    "\n",
    "val_dataloader = DataLoader(dataset = val_dataset,\n",
    "                           shuffle = True,\n",
    "                           batch_size = 128)\n",
    "\n",
    "# Test Dataset\n",
    "test_dataset = CelebADataset(dataframe = test_df,\n",
    "                            img_dir = DATA_DIR,\n",
    "                            transform = custom_transform)\n",
    "\n",
    "test_dataloader = DataLoader(dataset = test_dataset,\n",
    "                            shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6d2f264-0254-4c16-820f-7d118c4cb87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet 34 model for Age Prediction\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "## Resnet Block\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride = stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes, stride = 1)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "## ResNet\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes, grayscale):\n",
    "        self.num_classes = num_classes\n",
    "        self.inplanes = 64\n",
    "        if grayscale:\n",
    "            in_dim = 1\n",
    "        else:\n",
    "            in_dim = 3\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_dim, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1, padding=2)\n",
    "        self.fc = nn.Linear(2048 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, (2. / n)**.5)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        logits = F.softmax(self.fc(x), dim  = 1)\n",
    "        return logits\n",
    "\n",
    "## ResNet 34 model\n",
    "def resnet34(num_classes):\n",
    "    \"\"\"Constructs a ResNet-34 model.\"\"\"\n",
    "    model = ResNet(block=BasicBlock,\n",
    "                   layers=[3, 4, 6, 3],\n",
    "                   num_classes=num_classes,\n",
    "                   grayscale=GRAYSCALE)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f43ab6e-f58d-4030-9990-ad641baf6e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_cnn(model, train_dataloader, val_dataloader, epochs = 10, lr =1e-3, wd= 1e-5, verbose = True):\n",
    "    optimizer = optim.Adam(model.parameters(), lr = lr, weight_decay = wd)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Training Model...............\")\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        tloss = 0\n",
    "        tloss_num = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        model.train()\n",
    "        for batch_idx, data in enumerate(train_dataloader):\n",
    "            x, y = data\n",
    "            x = x.to(torch.float32).to(device)\n",
    "            y = y.to(torch.long).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x)\n",
    "            loss = F.cross_entropy(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            tloss += loss.detach().cpu()\n",
    "            tloss_num += 1\n",
    "\n",
    "            _, preds = torch.max(out.data, 1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.shape[0]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            vloss = 0\n",
    "            vloss_num = 0\n",
    "            vcorrect = 0\n",
    "            vtotal = 0\n",
    "\n",
    "            for batch_idx, data in enumerate(val_dataloader):\n",
    "                x, y = data\n",
    "                x = x.to(torch.float32).to(device)\n",
    "                y = y.to(torch.long).to(device)\n",
    "\n",
    "                out = model(x)\n",
    "                loss = F.cross_entropy(out, y)\n",
    "\n",
    "                vloss += loss.detach().cpu()\n",
    "                vloss_num +=1\n",
    "\n",
    "                _, preds = torch.max(out.data, 1)\n",
    "                vcorrect += (preds == y).sum().item()\n",
    "                vtotal += y.shape[0]\n",
    "\n",
    "        train_losses.append(float(tloss / tloss_num))\n",
    "        train_accs.append(float(correct/total))\n",
    "        val_losses.append(float(vloss / vloss_num))\n",
    "        val_accs.append(float(vcorrect / vtotal))\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Epoch :{epoch}/{epochs}\")\n",
    "            print(f\"Training Loss: {tloss / tloss_num} Accuracy: {correct / total}\")\n",
    "            print(f\"Validation Loss: {vloss / vloss_num} Accuracy: {vcorrect / vtotal}\")\n",
    "\n",
    "    return model, train_losses, train_accs, val_losses, val_accs\n",
    "\n",
    "def eval_cnn(model, test_dataloader):\n",
    "    model.eval()\n",
    "    tloss = 0\n",
    "    tloss_num = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    for batch_idx, data in enumerate(test_dataloader):\n",
    "        x, y = data\n",
    "        x = x.to(torch.float32).to(device)\n",
    "        y = y.to(torch.long).to(device)\n",
    "\n",
    "        out = model(x)\n",
    "        loss = F.cross_entropy(out, y)\n",
    "\n",
    "        tloss += loss.detach().cpu()\n",
    "        tloss_num += 1\n",
    "\n",
    "        _, preds = torch.max(out.data, 1)\n",
    "        total += y.shape[0]\n",
    "        correct += (preds == y).sum().item()\n",
    "\n",
    "    print(f\"Test Loss: {tloss / tloss_num} Accuracy:{correct / total}\")\n",
    "    return tloss / tloss_num, correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39eb7974-61bd-4c7e-a4c7-a6b180b418c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves(train_loss, val_loss, test_loss, model_name, metric = \"loss\", epochs = 100):\n",
    "    plt.plot(range(epochs), train_loss, color = \"blue\", label = f\"Training {metric}\")\n",
    "    plt.plot(range(epochs), val_loss, color = \"red\", label = f\"Validation {metric}\")\n",
    "    plt.plot(range(epochs), [test_loss] * epochs, color = \"green\", label = f\"Test {metric}\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.title(model_name)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7a6c7b8-ec95-4afe-bb98-bdd58b630ee4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 64, 64]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 64, 64]             128\n",
      "              ReLU-3           [-1, 64, 64, 64]               0\n",
      "         MaxPool2d-4           [-1, 64, 32, 32]               0\n",
      "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
      "              ReLU-7           [-1, 64, 32, 32]               0\n",
      "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
      "             ReLU-10           [-1, 64, 32, 32]               0\n",
      "       BasicBlock-11           [-1, 64, 32, 32]               0\n",
      "           Conv2d-12           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 32, 32]             128\n",
      "             ReLU-14           [-1, 64, 32, 32]               0\n",
      "           Conv2d-15           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 32, 32]             128\n",
      "             ReLU-17           [-1, 64, 32, 32]               0\n",
      "       BasicBlock-18           [-1, 64, 32, 32]               0\n",
      "           Conv2d-19           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-20           [-1, 64, 32, 32]             128\n",
      "             ReLU-21           [-1, 64, 32, 32]               0\n",
      "           Conv2d-22           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-23           [-1, 64, 32, 32]             128\n",
      "             ReLU-24           [-1, 64, 32, 32]               0\n",
      "       BasicBlock-25           [-1, 64, 32, 32]               0\n",
      "           Conv2d-26          [-1, 128, 16, 16]          73,728\n",
      "      BatchNorm2d-27          [-1, 128, 16, 16]             256\n",
      "             ReLU-28          [-1, 128, 16, 16]               0\n",
      "           Conv2d-29          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-30          [-1, 128, 16, 16]             256\n",
      "           Conv2d-31          [-1, 128, 16, 16]           8,192\n",
      "      BatchNorm2d-32          [-1, 128, 16, 16]             256\n",
      "             ReLU-33          [-1, 128, 16, 16]               0\n",
      "       BasicBlock-34          [-1, 128, 16, 16]               0\n",
      "           Conv2d-35          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-36          [-1, 128, 16, 16]             256\n",
      "             ReLU-37          [-1, 128, 16, 16]               0\n",
      "           Conv2d-38          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-39          [-1, 128, 16, 16]             256\n",
      "             ReLU-40          [-1, 128, 16, 16]               0\n",
      "       BasicBlock-41          [-1, 128, 16, 16]               0\n",
      "           Conv2d-42          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-43          [-1, 128, 16, 16]             256\n",
      "             ReLU-44          [-1, 128, 16, 16]               0\n",
      "           Conv2d-45          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-46          [-1, 128, 16, 16]             256\n",
      "             ReLU-47          [-1, 128, 16, 16]               0\n",
      "       BasicBlock-48          [-1, 128, 16, 16]               0\n",
      "           Conv2d-49          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-50          [-1, 128, 16, 16]             256\n",
      "             ReLU-51          [-1, 128, 16, 16]               0\n",
      "           Conv2d-52          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 16, 16]             256\n",
      "             ReLU-54          [-1, 128, 16, 16]               0\n",
      "       BasicBlock-55          [-1, 128, 16, 16]               0\n",
      "           Conv2d-56            [-1, 256, 8, 8]         294,912\n",
      "      BatchNorm2d-57            [-1, 256, 8, 8]             512\n",
      "             ReLU-58            [-1, 256, 8, 8]               0\n",
      "           Conv2d-59            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-60            [-1, 256, 8, 8]             512\n",
      "           Conv2d-61            [-1, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-62            [-1, 256, 8, 8]             512\n",
      "             ReLU-63            [-1, 256, 8, 8]               0\n",
      "       BasicBlock-64            [-1, 256, 8, 8]               0\n",
      "           Conv2d-65            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-66            [-1, 256, 8, 8]             512\n",
      "             ReLU-67            [-1, 256, 8, 8]               0\n",
      "           Conv2d-68            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-69            [-1, 256, 8, 8]             512\n",
      "             ReLU-70            [-1, 256, 8, 8]               0\n",
      "       BasicBlock-71            [-1, 256, 8, 8]               0\n",
      "           Conv2d-72            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-73            [-1, 256, 8, 8]             512\n",
      "             ReLU-74            [-1, 256, 8, 8]               0\n",
      "           Conv2d-75            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-76            [-1, 256, 8, 8]             512\n",
      "             ReLU-77            [-1, 256, 8, 8]               0\n",
      "       BasicBlock-78            [-1, 256, 8, 8]               0\n",
      "           Conv2d-79            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-80            [-1, 256, 8, 8]             512\n",
      "             ReLU-81            [-1, 256, 8, 8]               0\n",
      "           Conv2d-82            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-83            [-1, 256, 8, 8]             512\n",
      "             ReLU-84            [-1, 256, 8, 8]               0\n",
      "       BasicBlock-85            [-1, 256, 8, 8]               0\n",
      "           Conv2d-86            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-87            [-1, 256, 8, 8]             512\n",
      "             ReLU-88            [-1, 256, 8, 8]               0\n",
      "           Conv2d-89            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-90            [-1, 256, 8, 8]             512\n",
      "             ReLU-91            [-1, 256, 8, 8]               0\n",
      "       BasicBlock-92            [-1, 256, 8, 8]               0\n",
      "           Conv2d-93            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-94            [-1, 256, 8, 8]             512\n",
      "             ReLU-95            [-1, 256, 8, 8]               0\n",
      "           Conv2d-96            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-97            [-1, 256, 8, 8]             512\n",
      "             ReLU-98            [-1, 256, 8, 8]               0\n",
      "       BasicBlock-99            [-1, 256, 8, 8]               0\n",
      "          Conv2d-100            [-1, 512, 4, 4]       1,179,648\n",
      "     BatchNorm2d-101            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-102            [-1, 512, 4, 4]               0\n",
      "          Conv2d-103            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-104            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-105            [-1, 512, 4, 4]         131,072\n",
      "     BatchNorm2d-106            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-107            [-1, 512, 4, 4]               0\n",
      "      BasicBlock-108            [-1, 512, 4, 4]               0\n",
      "          Conv2d-109            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-110            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-111            [-1, 512, 4, 4]               0\n",
      "          Conv2d-112            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-113            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-114            [-1, 512, 4, 4]               0\n",
      "      BasicBlock-115            [-1, 512, 4, 4]               0\n",
      "          Conv2d-116            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-117            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-118            [-1, 512, 4, 4]               0\n",
      "          Conv2d-119            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-120            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-121            [-1, 512, 4, 4]               0\n",
      "      BasicBlock-122            [-1, 512, 4, 4]               0\n",
      "       AvgPool2d-123            [-1, 512, 2, 2]               0\n",
      "          Linear-124                    [-1, 2]           4,098\n",
      "================================================================\n",
      "Total params: 21,288,770\n",
      "Trainable params: 21,288,770\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 31.45\n",
      "Params size (MB): 81.21\n",
      "Estimated Total Size (MB): 112.85\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = resnet34(2).to(device)\n",
    "summary(model,(3, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f77be3c-7636-440b-8835-d3ea6c3c8661",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                  | 0/10 [00:34<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m resnet34(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 2\u001b[0m model, train_losses, train_accs, val_losses, val_accs \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_cnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m eval_cnn(model, test_dataloader)\n",
      "Cell \u001b[0;32mIn[31], line 31\u001b[0m, in \u001b[0;36mtrain_cnn\u001b[0;34m(model, train_dataloader, val_dataloader, epochs, lr, wd, verbose)\u001b[0m\n\u001b[1;32m     28\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     29\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 31\u001b[0m tloss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m tloss_num \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     34\u001b[0m _, preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(out\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = resnet34(2).to(device)\n",
    "model, train_losses, train_accs, val_losses, val_accs = train_cnn(model, train_dataloader, val_dataloader, epochs = 10, verbose = False)\n",
    "test_loss, test_acc = eval_cnn(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b9aa0e-6168-444d-b78b-29fe52e08bb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_loss_curves(train_losses, val_losses, test_loss, model_name = \"CNN Loss Curves\", metric = \"loss\", epochs = 10)\n",
    "plot_loss_curves(train_accs, val_accs, test_acc, model_name = \"CNN Accuracy Currves\", metric = \"Accuracy\", epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e910c5-48e0-43b6-8a41-fdd8cd4bff10",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77c3823b-a01e-4c34-87f4-7bdf954789ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:32<00:00, 332.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3759952783584595 Accuracy:0.9351694183263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:29<00:00, 329.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.37796929478645325 Accuracy:0.9330470620172256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.37806519865989685 Accuracy:0.9342316329804299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.36727070808410645 Accuracy:0.9431899508896622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.36684155464172363 Accuracy:0.9440783791120654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3710487484931946 Accuracy:0.9384023099133783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3900444507598877 Accuracy:0.9197206386811777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:30<00:00, 330.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.37999433279037476 Accuracy:0.9308506700229511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:33<00:00, 333.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.39930400252342224 Accuracy:0.910095999605143\n",
      "Best LR: 0.0001\n",
      "Best Weight decay: 0.0001\n"
     ]
    }
   ],
   "source": [
    "lrs = [1e-5, 1e-4, 1e-3]\n",
    "wds = [1e-5, 1e-4, 1e-3]\n",
    "\n",
    "test_accs = np.zeros((len(lrs), len(wds)))\n",
    "\n",
    "for lr in range(len(lrs)):\n",
    "    for wd in range(len(wds)):\n",
    "        model = resnet34(2).to(device)\n",
    "        model, train_losses, train_accs, val_losses, val_accs = train_cnn(model, train_dataloader, val_dataloader, epochs = 1, lr= lrs[lr], wd = wds[wd], verbose = False)\n",
    "        test_loss, test_acc = eval_cnn(model, test_dataloader)\n",
    "\n",
    "        test_accs[lr, wd] = test_acc\n",
    "\n",
    "best_lr, best_wd = np.unravel_index(np.argmax(test_accs), test_accs.shape)\n",
    "print(f\"Best LR: {lrs[best_lr]}\")\n",
    "print(f\"Best Weight decay: {wds[best_wd]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bf408f9-f79f-4a81-920e-1b5f9315d64f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LR: 1\n",
      "Best Weight decay: 1\n"
     ]
    }
   ],
   "source": [
    "lrs = [1e-5, 1e-4, 1e-3]\n",
    "wds = [1e-5, 1e-4, 1e-3]\n",
    "\n",
    "best_lr = 1\n",
    "best_wd = 1\n",
    "# best_lr, best_wd = np.unravel_index(np.argmax(test_accs), test_accs.shape)\n",
    "print(f\"Best LR: {best_lr}\")\n",
    "print(f\"Best Weight decay: {best_wd}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba32849a-14e9-44ab-8eec-d9690a8502b0",
   "metadata": {},
   "source": [
    "### Finetuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4a381e5-bace-4923-a0e1-bb6749e2d671",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [54:57<00:00, 329.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.36093124747276306 Accuracy:0.9504454480392883\n"
     ]
    }
   ],
   "source": [
    "model = resnet34(2).to(device)\n",
    "model, train_losses, train_accs, val_losses, val_accs = train_cnn(model, train_dataloader, val_dataloader, epochs = 10, lr = lrs[best_lr], wd = wds[best_wd], verbose = False)\n",
    "test_loss, test_acc = eval_cnn(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cda08af-9839-4c68-81da-7e8c9b9851c5",
   "metadata": {},
   "source": [
    "## Group wise Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9aa27ba-d85a-4682-9041-035516c43586",
   "metadata": {},
   "outputs": [],
   "source": [
    "#male blond dataloader\n",
    "male_blond_dataset = CelebADataset(dataframe = male_blond_df,\n",
    "                            img_dir = DATA_DIR,\n",
    "                            transform = custom_transform)\n",
    "male_blond_dataloader = DataLoader(dataset = male_blond_dataset,\n",
    "                                  shuffle = True,\n",
    "                                  batch_size= 128)\n",
    "\n",
    "#female blond dataset\n",
    "female_blond_dataset = CelebADataset(dataframe = female_blond_df,\n",
    "                                    img_dir = DATA_DIR,\n",
    "                                    transform = custom_transform)\n",
    "female_blond_dataloader = DataLoader(dataset = female_blond_dataset,\n",
    "                                    shuffle = True,\n",
    "                                    batch_size = 128)\n",
    "\n",
    "#male non blond dataset\n",
    "male_non_blond_dataset = CelebADataset(dataframe = male_non_blond_df,\n",
    "                                      img_dir = DATA_DIR,\n",
    "                                      transform = custom_transform)\n",
    "male_non_blond_dataloader = DataLoader(dataset = male_non_blond_dataset,\n",
    "                                      shuffle = True,\n",
    "                                      batch_size = 128)\n",
    "\n",
    "#female non blond dataloader\n",
    "female_non_blond_dataset = CelebADataset(dataframe = female_non_blond_df,\n",
    "                                        img_dir = DATA_DIR,\n",
    "                                        transform = custom_transform)\n",
    "\n",
    "female_non_blond_dataloader = DataLoader(dataset = female_non_blond_dataset,\n",
    "                                        shuffle = True,\n",
    "                                        batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5933c27-7aaa-43ad-b164-46aa327bced6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric: mean group accuracy:\n",
    "groups = [male_blond_dataloader, female_blond_dataloader, male_non_blond_dataloader, female_non_blond_dataloader]\n",
    "\n",
    "def mean_group(model, groups, type = \"cnn\"):\n",
    "    group_wise_acc_fs = []\n",
    "    group_wise_loss_fs = []\n",
    "    groups = [male_blond_dataloader, female_blond_dataloader, male_non_blond_dataloader, female_non_blond_dataloader]\n",
    "    \n",
    "    for group in range(len(groups)):\n",
    "        if type == \"cnn\":\n",
    "            loss, acc = eval_cnn(model, groups[group])\n",
    "        else:\n",
    "            loss, acc = eval_fsmodel(model, groups[group])\n",
    "            \n",
    "        group_wise_acc_fs.append(acc)\n",
    "        group_wise_loss_fs.append(loss)\n",
    "    \n",
    "    mean_group_acc = np.mean(group_wise_acc_fs)\n",
    "    mean_group_loss = np.mean(group_wise_loss_fs)\n",
    "    \n",
    "    print(f\"Mean group accuracy: {mean_group_acc}\")\n",
    "    print(f\"Mean group loss: {mean_group_loss}\")\n",
    "    return mean_group_acc, mean_group_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d6581db-0766-4828-917a-263dfa677b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.863316535949707 Accuracy:0.4326647564469914\n",
      "Test Loss: 0.48938846588134766 Accuracy:0.8174760787145694\n",
      "Test Loss: 0.323468953371048 Accuracy:0.9887747790780989\n",
      "Test Loss: 0.346209317445755 Accuracy:0.9647190383002516\n",
      "Mean group wise accuracy: 0.8009086631349778\n",
      "Mean group wise Loss: 0.5055958032608032\n"
     ]
    }
   ],
   "source": [
    "group_wise_acc = []\n",
    "group_wise_loss = []\n",
    "groups = [male_blond_dataloader, female_blond_dataloader, male_non_blond_dataloader, female_non_blond_dataloader]\n",
    "\n",
    "for group in range(len(groups)):\n",
    "    loss, acc = eval_cnn(model, groups[group])\n",
    "    group_wise_acc.append(acc)\n",
    "    group_wise_loss.append(loss)\n",
    "\n",
    "mean_cnn_group_acc = np.mean(group_wise_acc)\n",
    "mean_cnn_group_loss= np.mean(group_wise_loss)\n",
    "print(f\"Mean group wise accuracy: {mean_cnn_group_acc}\")\n",
    "print(f\"Mean group wise Loss: {mean_cnn_group_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5afed8e-8d05-47fa-94d9-d65b6c39e228",
   "metadata": {},
   "source": [
    "## Feature Sieve Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f165cde-a8d4-420f-9228-69dcc59178ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature_Sieve(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes, grayscale):\n",
    "        self.num_classes = num_classes\n",
    "        self.inplanes = 64\n",
    "        if grayscale:\n",
    "            in_dim = 1\n",
    "        else:\n",
    "            in_dim = 3\n",
    "        super(Feature_Sieve, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_dim, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1, padding=2)\n",
    "        self.fc = nn.Linear(2048 * block.expansion, self.num_classes)\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.auxlayer1 = self._make_layer(block, 64, layers[0], stride = 2)\n",
    "        self.auxlayer2 = self._make_layer(block,  64, layers[1], stride=2)\n",
    "        # self.auxlayer3 = self._make_layer(block, 128, layers[2], stride = 2)\n",
    "        self.aux_avgpool = nn.AvgPool2d(7, stride=1, padding=2)\n",
    "        self.aux_fc = nn.Linear(4096, self.num_classes)\n",
    "        # self.aux_out = nn.Linear(128, 1)\n",
    "        \n",
    "\n",
    "        self.params = nn.ModuleDict({\n",
    "            \"main\": nn.ModuleList([self.conv1, self.bn1, self.relu, self.maxpool, self.layer1, self.layer2, self.layer3, self.layer4, self.avgpool, self.fc]),\n",
    "            \"aux\": nn.ModuleList([ self.auxlayer1, self.auxlayer2, self.aux_avgpool, self.aux_fc]),\n",
    "            \"forget\": nn.ModuleList([self.conv1, self.bn1, self.relu, self.maxpool, self.layer1])\n",
    "        })\n",
    "\n",
    "    \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, (2. / n)**.5)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "        \n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "\n",
    "        #forward of the main network\n",
    "        sh = self.layer1(x)\n",
    "        x = self.layer2(sh)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        logits = self.fc(x)\n",
    "\n",
    "        #forward of aux network\n",
    "        aux = self.auxlayer1(sh)\n",
    "        aux = self.auxlayer2(aux)\n",
    "        # aux = self.auxlayer3(aux)\n",
    "        # aux = self.aux_avgpool(aux)\n",
    "        aux = aux.view(aux.size(0), -1)\n",
    "        aux = self.aux_fc(aux)\n",
    "        # aux = self.aux_out(aux)\n",
    "        \n",
    "        \n",
    "        return logits, aux\n",
    "\n",
    "def feature_sieve(num_classes, grayscale):\n",
    "    \"\"\"Constructs a ResNet-34 model.\"\"\"\n",
    "    model = Feature_Sieve(block=BasicBlock,\n",
    "                   layers=[3, 4, 6, 3],\n",
    "                   num_classes=num_classes,\n",
    "                   grayscale=grayscale)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0388bf5-72fd-4a50-bba7-64f12514b60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_main(FS, optim_main, x, y):\n",
    "    FS.train()\n",
    "    optim_main.zero_grad()\n",
    "    out = FS(x)[0]\n",
    "    loss = F.cross_entropy(out, y)\n",
    "    loss.backward()\n",
    "    optim_main.step()\n",
    "    optim_main.zero_grad()\n",
    "    FS.eval()\n",
    "\n",
    "def learn_aux(FS, optim_main, optim_aux, x, y, alpha_aux=1):\n",
    "    FS.train()\n",
    "    optim_main.zero_grad()\n",
    "    aux = FS(x)[1]\n",
    "    loss = alpha_aux * F.cross_entropy(aux, y)\n",
    "    loss.backward()\n",
    "    optim_aux.step()\n",
    "    optim_aux.zero_grad()\n",
    "    FS.eval()\n",
    "\n",
    "def forget_aux(FS, optim_forget, x, num_bins):\n",
    "    FS.train()\n",
    "    optim_forget.zero_grad()\n",
    "    aux = FS(x)[1]\n",
    "    loss = F.cross_entropy(aux, torch.ones_like(aux) * 1/num_bins)\n",
    "    loss.backward()\n",
    "    optim_forget.step()\n",
    "    optim_forget.zero_grad()\n",
    "    FS.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47873b20-f50c-4dc7-94cd-7fa7e0b59744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fs(model, train_dataloader, val_dataloader, forget_iters = 5, aux_iters =1, main_iters =1, lrs = [0.0005, 0.0005, 0.0005],epochs = 100, verbose = False, patience = 3, min_delta = 0.1):\n",
    "    if verbose:\n",
    "        print(\"Training Model..............\")\n",
    "\n",
    "    optim_main = optim.Adam(model.params.main.parameters())\n",
    "    optim_aux = optim.Adam(model.params.aux.parameters())\n",
    "    optim_forget = optim.Adam(model.params.forget.parameters())\n",
    "\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "\n",
    "    steps = 0\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        tloss = 0\n",
    "        tloss_num = 0\n",
    "        tcorrect = 0\n",
    "        ttotal = 0\n",
    "\n",
    "        for batch_idx, data in enumerate(train_dataloader):\n",
    "            x, y = data\n",
    "            x = x.to(torch.float32).to(device)\n",
    "            y = y.to(torch.long).to(device)\n",
    "        \n",
    "            if main_iters and steps % main_iters == 0:\n",
    "                learn_main(model, optim_main, x, y)\n",
    "            if aux_iters and steps % aux_iters == 0:\n",
    "                learn_aux(model, optim_main, optim_aux, x, y)\n",
    "            if forget_iters and steps % forget_iters == 0:\n",
    "                forget_aux(model, optim_forget, x, model.num_classes)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                out = model(x)[0]\n",
    "                loss = F.cross_entropy(out, y)\n",
    "                tloss += loss.detach().cpu()\n",
    "                tloss_num += 1\n",
    "\n",
    "                _, preds = torch.max(out.data, 1)\n",
    "                tcorrect += (preds == y).sum().item()\n",
    "                ttotal += y.shape[0]\n",
    "                steps += 1\n",
    "\n",
    "        with torch.no_grad():\n",
    "            vloss = 0\n",
    "            vloss_num = 0\n",
    "            vtotal = 0\n",
    "            vcorrect = 0\n",
    "\n",
    "            for batch_idx, data in enumerate(val_dataloader):\n",
    "                x, y = data\n",
    "                x = x.to(torch.float32).to(device)\n",
    "                y = y.to(torch.long).to(device)\n",
    "\n",
    "                out = model(x)[0]\n",
    "                loss = F.cross_entropy(out, y)\n",
    "                vloss += loss.detach().cpu()\n",
    "                vloss_num += 1\n",
    "\n",
    "                _, preds = torch.max(out.data, 1)\n",
    "                vtotal += y.shape[0]\n",
    "                vcorrect += (preds == y).sum().item()\n",
    "\n",
    "        train_losses.append(tloss / tloss_num)\n",
    "        train_accs.append(tcorrect / ttotal)\n",
    "        val_losses.append(vloss / vloss_num)\n",
    "        val_accs.append(vcorrect /  vtotal)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Epoch: {epoch} / {epochs}\")\n",
    "            print(f\"Training Loss: {tloss / tloss_num} Accuracy: {tcorrect / ttotal}\")\n",
    "            print(f\"Validation Loss: {vloss / vloss_num} Accuracy: {vcorrect / vtotal}\")\n",
    "\n",
    "    return model, train_losses, train_accs, val_losses, val_accs\n",
    "\n",
    "def eval_fsmodel(model, test_dataloader):\n",
    "    tloss = 0\n",
    "    tloss_num = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(test_dataloader):\n",
    "            x, y = data\n",
    "            x = x.to(torch.float32).to(device)\n",
    "            y= y.to(torch.long).to(device)\n",
    "\n",
    "            out = model(x)[0]\n",
    "            loss = F.cross_entropy(out, y)\n",
    "            tloss += loss.detach().cpu()\n",
    "            tloss_num += 1\n",
    "\n",
    "            _, preds = torch.max(out.data, 1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.shape[0]\n",
    "\n",
    "    test_loss = tloss / tloss_num\n",
    "    test_acc = correct / total\n",
    "\n",
    "    print(f\"Test Loss: {test_loss} Test Accuracy :{test_acc}\")\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb4ad18a-f2dd-492d-9309-874dad785c06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 64, 64]           9,408\n",
      "            Conv2d-2           [-1, 64, 64, 64]           9,408\n",
      "            Conv2d-3           [-1, 64, 64, 64]           9,408\n",
      "       BatchNorm2d-4           [-1, 64, 64, 64]             128\n",
      "       BatchNorm2d-5           [-1, 64, 64, 64]             128\n",
      "       BatchNorm2d-6           [-1, 64, 64, 64]             128\n",
      "              ReLU-7           [-1, 64, 64, 64]               0\n",
      "              ReLU-8           [-1, 64, 64, 64]               0\n",
      "              ReLU-9           [-1, 64, 64, 64]               0\n",
      "        MaxPool2d-10           [-1, 64, 32, 32]               0\n",
      "        MaxPool2d-11           [-1, 64, 32, 32]               0\n",
      "        MaxPool2d-12           [-1, 64, 32, 32]               0\n",
      "           Conv2d-13           [-1, 64, 32, 32]          36,864\n",
      "           Conv2d-14           [-1, 64, 32, 32]          36,864\n",
      "           Conv2d-15           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 32, 32]             128\n",
      "      BatchNorm2d-17           [-1, 64, 32, 32]             128\n",
      "      BatchNorm2d-18           [-1, 64, 32, 32]             128\n",
      "             ReLU-19           [-1, 64, 32, 32]               0\n",
      "             ReLU-20           [-1, 64, 32, 32]               0\n",
      "             ReLU-21           [-1, 64, 32, 32]               0\n",
      "           Conv2d-22           [-1, 64, 32, 32]          36,864\n",
      "           Conv2d-23           [-1, 64, 32, 32]          36,864\n",
      "           Conv2d-24           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-25           [-1, 64, 32, 32]             128\n",
      "      BatchNorm2d-26           [-1, 64, 32, 32]             128\n",
      "      BatchNorm2d-27           [-1, 64, 32, 32]             128\n",
      "             ReLU-28           [-1, 64, 32, 32]               0\n",
      "             ReLU-29           [-1, 64, 32, 32]               0\n",
      "             ReLU-30           [-1, 64, 32, 32]               0\n",
      "       BasicBlock-31           [-1, 64, 32, 32]               0\n",
      "       BasicBlock-32           [-1, 64, 32, 32]               0\n",
      "       BasicBlock-33           [-1, 64, 32, 32]               0\n",
      "           Conv2d-34           [-1, 64, 32, 32]          36,864\n",
      "           Conv2d-35           [-1, 64, 32, 32]          36,864\n",
      "           Conv2d-36           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-37           [-1, 64, 32, 32]             128\n",
      "      BatchNorm2d-38           [-1, 64, 32, 32]             128\n",
      "      BatchNorm2d-39           [-1, 64, 32, 32]             128\n",
      "             ReLU-40           [-1, 64, 32, 32]               0\n",
      "             ReLU-41           [-1, 64, 32, 32]               0\n",
      "             ReLU-42           [-1, 64, 32, 32]               0\n",
      "           Conv2d-43           [-1, 64, 32, 32]          36,864\n",
      "           Conv2d-44           [-1, 64, 32, 32]          36,864\n",
      "           Conv2d-45           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-46           [-1, 64, 32, 32]             128\n",
      "      BatchNorm2d-47           [-1, 64, 32, 32]             128\n",
      "      BatchNorm2d-48           [-1, 64, 32, 32]             128\n",
      "             ReLU-49           [-1, 64, 32, 32]               0\n",
      "             ReLU-50           [-1, 64, 32, 32]               0\n",
      "             ReLU-51           [-1, 64, 32, 32]               0\n",
      "       BasicBlock-52           [-1, 64, 32, 32]               0\n",
      "       BasicBlock-53           [-1, 64, 32, 32]               0\n",
      "       BasicBlock-54           [-1, 64, 32, 32]               0\n",
      "           Conv2d-55           [-1, 64, 32, 32]          36,864\n",
      "           Conv2d-56           [-1, 64, 32, 32]          36,864\n",
      "           Conv2d-57           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-58           [-1, 64, 32, 32]             128\n",
      "      BatchNorm2d-59           [-1, 64, 32, 32]             128\n",
      "      BatchNorm2d-60           [-1, 64, 32, 32]             128\n",
      "             ReLU-61           [-1, 64, 32, 32]               0\n",
      "             ReLU-62           [-1, 64, 32, 32]               0\n",
      "             ReLU-63           [-1, 64, 32, 32]               0\n",
      "           Conv2d-64           [-1, 64, 32, 32]          36,864\n",
      "           Conv2d-65           [-1, 64, 32, 32]          36,864\n",
      "           Conv2d-66           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-67           [-1, 64, 32, 32]             128\n",
      "      BatchNorm2d-68           [-1, 64, 32, 32]             128\n",
      "      BatchNorm2d-69           [-1, 64, 32, 32]             128\n",
      "             ReLU-70           [-1, 64, 32, 32]               0\n",
      "             ReLU-71           [-1, 64, 32, 32]               0\n",
      "             ReLU-72           [-1, 64, 32, 32]               0\n",
      "       BasicBlock-73           [-1, 64, 32, 32]               0\n",
      "       BasicBlock-74           [-1, 64, 32, 32]               0\n",
      "       BasicBlock-75           [-1, 64, 32, 32]               0\n",
      "           Conv2d-76          [-1, 128, 16, 16]          73,728\n",
      "           Conv2d-77          [-1, 128, 16, 16]          73,728\n",
      "      BatchNorm2d-78          [-1, 128, 16, 16]             256\n",
      "      BatchNorm2d-79          [-1, 128, 16, 16]             256\n",
      "             ReLU-80          [-1, 128, 16, 16]               0\n",
      "             ReLU-81          [-1, 128, 16, 16]               0\n",
      "           Conv2d-82          [-1, 128, 16, 16]         147,456\n",
      "           Conv2d-83          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-84          [-1, 128, 16, 16]             256\n",
      "      BatchNorm2d-85          [-1, 128, 16, 16]             256\n",
      "           Conv2d-86          [-1, 128, 16, 16]           8,192\n",
      "           Conv2d-87          [-1, 128, 16, 16]           8,192\n",
      "      BatchNorm2d-88          [-1, 128, 16, 16]             256\n",
      "      BatchNorm2d-89          [-1, 128, 16, 16]             256\n",
      "             ReLU-90          [-1, 128, 16, 16]               0\n",
      "             ReLU-91          [-1, 128, 16, 16]               0\n",
      "       BasicBlock-92          [-1, 128, 16, 16]               0\n",
      "       BasicBlock-93          [-1, 128, 16, 16]               0\n",
      "           Conv2d-94          [-1, 128, 16, 16]         147,456\n",
      "           Conv2d-95          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-96          [-1, 128, 16, 16]             256\n",
      "      BatchNorm2d-97          [-1, 128, 16, 16]             256\n",
      "             ReLU-98          [-1, 128, 16, 16]               0\n",
      "             ReLU-99          [-1, 128, 16, 16]               0\n",
      "          Conv2d-100          [-1, 128, 16, 16]         147,456\n",
      "          Conv2d-101          [-1, 128, 16, 16]         147,456\n",
      "     BatchNorm2d-102          [-1, 128, 16, 16]             256\n",
      "     BatchNorm2d-103          [-1, 128, 16, 16]             256\n",
      "            ReLU-104          [-1, 128, 16, 16]               0\n",
      "            ReLU-105          [-1, 128, 16, 16]               0\n",
      "      BasicBlock-106          [-1, 128, 16, 16]               0\n",
      "      BasicBlock-107          [-1, 128, 16, 16]               0\n",
      "          Conv2d-108          [-1, 128, 16, 16]         147,456\n",
      "          Conv2d-109          [-1, 128, 16, 16]         147,456\n",
      "     BatchNorm2d-110          [-1, 128, 16, 16]             256\n",
      "     BatchNorm2d-111          [-1, 128, 16, 16]             256\n",
      "            ReLU-112          [-1, 128, 16, 16]               0\n",
      "            ReLU-113          [-1, 128, 16, 16]               0\n",
      "          Conv2d-114          [-1, 128, 16, 16]         147,456\n",
      "          Conv2d-115          [-1, 128, 16, 16]         147,456\n",
      "     BatchNorm2d-116          [-1, 128, 16, 16]             256\n",
      "     BatchNorm2d-117          [-1, 128, 16, 16]             256\n",
      "            ReLU-118          [-1, 128, 16, 16]               0\n",
      "            ReLU-119          [-1, 128, 16, 16]               0\n",
      "      BasicBlock-120          [-1, 128, 16, 16]               0\n",
      "      BasicBlock-121          [-1, 128, 16, 16]               0\n",
      "          Conv2d-122          [-1, 128, 16, 16]         147,456\n",
      "          Conv2d-123          [-1, 128, 16, 16]         147,456\n",
      "     BatchNorm2d-124          [-1, 128, 16, 16]             256\n",
      "     BatchNorm2d-125          [-1, 128, 16, 16]             256\n",
      "            ReLU-126          [-1, 128, 16, 16]               0\n",
      "            ReLU-127          [-1, 128, 16, 16]               0\n",
      "          Conv2d-128          [-1, 128, 16, 16]         147,456\n",
      "          Conv2d-129          [-1, 128, 16, 16]         147,456\n",
      "     BatchNorm2d-130          [-1, 128, 16, 16]             256\n",
      "     BatchNorm2d-131          [-1, 128, 16, 16]             256\n",
      "            ReLU-132          [-1, 128, 16, 16]               0\n",
      "            ReLU-133          [-1, 128, 16, 16]               0\n",
      "      BasicBlock-134          [-1, 128, 16, 16]               0\n",
      "      BasicBlock-135          [-1, 128, 16, 16]               0\n",
      "          Conv2d-136            [-1, 256, 8, 8]         294,912\n",
      "          Conv2d-137            [-1, 256, 8, 8]         294,912\n",
      "     BatchNorm2d-138            [-1, 256, 8, 8]             512\n",
      "     BatchNorm2d-139            [-1, 256, 8, 8]             512\n",
      "            ReLU-140            [-1, 256, 8, 8]               0\n",
      "            ReLU-141            [-1, 256, 8, 8]               0\n",
      "          Conv2d-142            [-1, 256, 8, 8]         589,824\n",
      "          Conv2d-143            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-144            [-1, 256, 8, 8]             512\n",
      "     BatchNorm2d-145            [-1, 256, 8, 8]             512\n",
      "          Conv2d-146            [-1, 256, 8, 8]          32,768\n",
      "          Conv2d-147            [-1, 256, 8, 8]          32,768\n",
      "     BatchNorm2d-148            [-1, 256, 8, 8]             512\n",
      "     BatchNorm2d-149            [-1, 256, 8, 8]             512\n",
      "            ReLU-150            [-1, 256, 8, 8]               0\n",
      "            ReLU-151            [-1, 256, 8, 8]               0\n",
      "      BasicBlock-152            [-1, 256, 8, 8]               0\n",
      "      BasicBlock-153            [-1, 256, 8, 8]               0\n",
      "          Conv2d-154            [-1, 256, 8, 8]         589,824\n",
      "          Conv2d-155            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-156            [-1, 256, 8, 8]             512\n",
      "     BatchNorm2d-157            [-1, 256, 8, 8]             512\n",
      "            ReLU-158            [-1, 256, 8, 8]               0\n",
      "            ReLU-159            [-1, 256, 8, 8]               0\n",
      "          Conv2d-160            [-1, 256, 8, 8]         589,824\n",
      "          Conv2d-161            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-162            [-1, 256, 8, 8]             512\n",
      "     BatchNorm2d-163            [-1, 256, 8, 8]             512\n",
      "            ReLU-164            [-1, 256, 8, 8]               0\n",
      "            ReLU-165            [-1, 256, 8, 8]               0\n",
      "      BasicBlock-166            [-1, 256, 8, 8]               0\n",
      "      BasicBlock-167            [-1, 256, 8, 8]               0\n",
      "          Conv2d-168            [-1, 256, 8, 8]         589,824\n",
      "          Conv2d-169            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-170            [-1, 256, 8, 8]             512\n",
      "     BatchNorm2d-171            [-1, 256, 8, 8]             512\n",
      "            ReLU-172            [-1, 256, 8, 8]               0\n",
      "            ReLU-173            [-1, 256, 8, 8]               0\n",
      "          Conv2d-174            [-1, 256, 8, 8]         589,824\n",
      "          Conv2d-175            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-176            [-1, 256, 8, 8]             512\n",
      "     BatchNorm2d-177            [-1, 256, 8, 8]             512\n",
      "            ReLU-178            [-1, 256, 8, 8]               0\n",
      "            ReLU-179            [-1, 256, 8, 8]               0\n",
      "      BasicBlock-180            [-1, 256, 8, 8]               0\n",
      "      BasicBlock-181            [-1, 256, 8, 8]               0\n",
      "          Conv2d-182            [-1, 256, 8, 8]         589,824\n",
      "          Conv2d-183            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-184            [-1, 256, 8, 8]             512\n",
      "     BatchNorm2d-185            [-1, 256, 8, 8]             512\n",
      "            ReLU-186            [-1, 256, 8, 8]               0\n",
      "            ReLU-187            [-1, 256, 8, 8]               0\n",
      "          Conv2d-188            [-1, 256, 8, 8]         589,824\n",
      "          Conv2d-189            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-190            [-1, 256, 8, 8]             512\n",
      "     BatchNorm2d-191            [-1, 256, 8, 8]             512\n",
      "            ReLU-192            [-1, 256, 8, 8]               0\n",
      "            ReLU-193            [-1, 256, 8, 8]               0\n",
      "      BasicBlock-194            [-1, 256, 8, 8]               0\n",
      "      BasicBlock-195            [-1, 256, 8, 8]               0\n",
      "          Conv2d-196            [-1, 256, 8, 8]         589,824\n",
      "          Conv2d-197            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-198            [-1, 256, 8, 8]             512\n",
      "     BatchNorm2d-199            [-1, 256, 8, 8]             512\n",
      "            ReLU-200            [-1, 256, 8, 8]               0\n",
      "            ReLU-201            [-1, 256, 8, 8]               0\n",
      "          Conv2d-202            [-1, 256, 8, 8]         589,824\n",
      "          Conv2d-203            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-204            [-1, 256, 8, 8]             512\n",
      "     BatchNorm2d-205            [-1, 256, 8, 8]             512\n",
      "            ReLU-206            [-1, 256, 8, 8]               0\n",
      "            ReLU-207            [-1, 256, 8, 8]               0\n",
      "      BasicBlock-208            [-1, 256, 8, 8]               0\n",
      "      BasicBlock-209            [-1, 256, 8, 8]               0\n",
      "          Conv2d-210            [-1, 256, 8, 8]         589,824\n",
      "          Conv2d-211            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-212            [-1, 256, 8, 8]             512\n",
      "     BatchNorm2d-213            [-1, 256, 8, 8]             512\n",
      "            ReLU-214            [-1, 256, 8, 8]               0\n",
      "            ReLU-215            [-1, 256, 8, 8]               0\n",
      "          Conv2d-216            [-1, 256, 8, 8]         589,824\n",
      "          Conv2d-217            [-1, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-218            [-1, 256, 8, 8]             512\n",
      "     BatchNorm2d-219            [-1, 256, 8, 8]             512\n",
      "            ReLU-220            [-1, 256, 8, 8]               0\n",
      "            ReLU-221            [-1, 256, 8, 8]               0\n",
      "      BasicBlock-222            [-1, 256, 8, 8]               0\n",
      "      BasicBlock-223            [-1, 256, 8, 8]               0\n",
      "          Conv2d-224            [-1, 512, 4, 4]       1,179,648\n",
      "          Conv2d-225            [-1, 512, 4, 4]       1,179,648\n",
      "     BatchNorm2d-226            [-1, 512, 4, 4]           1,024\n",
      "     BatchNorm2d-227            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-228            [-1, 512, 4, 4]               0\n",
      "            ReLU-229            [-1, 512, 4, 4]               0\n",
      "          Conv2d-230            [-1, 512, 4, 4]       2,359,296\n",
      "          Conv2d-231            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-232            [-1, 512, 4, 4]           1,024\n",
      "     BatchNorm2d-233            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-234            [-1, 512, 4, 4]         131,072\n",
      "          Conv2d-235            [-1, 512, 4, 4]         131,072\n",
      "     BatchNorm2d-236            [-1, 512, 4, 4]           1,024\n",
      "     BatchNorm2d-237            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-238            [-1, 512, 4, 4]               0\n",
      "            ReLU-239            [-1, 512, 4, 4]               0\n",
      "      BasicBlock-240            [-1, 512, 4, 4]               0\n",
      "      BasicBlock-241            [-1, 512, 4, 4]               0\n",
      "          Conv2d-242            [-1, 512, 4, 4]       2,359,296\n",
      "          Conv2d-243            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-244            [-1, 512, 4, 4]           1,024\n",
      "     BatchNorm2d-245            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-246            [-1, 512, 4, 4]               0\n",
      "            ReLU-247            [-1, 512, 4, 4]               0\n",
      "          Conv2d-248            [-1, 512, 4, 4]       2,359,296\n",
      "          Conv2d-249            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-250            [-1, 512, 4, 4]           1,024\n",
      "     BatchNorm2d-251            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-252            [-1, 512, 4, 4]               0\n",
      "            ReLU-253            [-1, 512, 4, 4]               0\n",
      "      BasicBlock-254            [-1, 512, 4, 4]               0\n",
      "      BasicBlock-255            [-1, 512, 4, 4]               0\n",
      "          Conv2d-256            [-1, 512, 4, 4]       2,359,296\n",
      "          Conv2d-257            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-258            [-1, 512, 4, 4]           1,024\n",
      "     BatchNorm2d-259            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-260            [-1, 512, 4, 4]               0\n",
      "            ReLU-261            [-1, 512, 4, 4]               0\n",
      "          Conv2d-262            [-1, 512, 4, 4]       2,359,296\n",
      "          Conv2d-263            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-264            [-1, 512, 4, 4]           1,024\n",
      "     BatchNorm2d-265            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-266            [-1, 512, 4, 4]               0\n",
      "            ReLU-267            [-1, 512, 4, 4]               0\n",
      "      BasicBlock-268            [-1, 512, 4, 4]               0\n",
      "      BasicBlock-269            [-1, 512, 4, 4]               0\n",
      "       AvgPool2d-270            [-1, 512, 2, 2]               0\n",
      "       AvgPool2d-271            [-1, 512, 2, 2]               0\n",
      "          Linear-272                    [-1, 2]           4,098\n",
      "          Linear-273                    [-1, 2]           4,098\n",
      "          Conv2d-274           [-1, 64, 16, 16]          36,864\n",
      "          Conv2d-275           [-1, 64, 16, 16]          36,864\n",
      "     BatchNorm2d-276           [-1, 64, 16, 16]             128\n",
      "     BatchNorm2d-277           [-1, 64, 16, 16]             128\n",
      "            ReLU-278           [-1, 64, 16, 16]               0\n",
      "            ReLU-279           [-1, 64, 16, 16]               0\n",
      "          Conv2d-280           [-1, 64, 16, 16]          36,864\n",
      "          Conv2d-281           [-1, 64, 16, 16]          36,864\n",
      "     BatchNorm2d-282           [-1, 64, 16, 16]             128\n",
      "     BatchNorm2d-283           [-1, 64, 16, 16]             128\n",
      "          Conv2d-284           [-1, 64, 16, 16]           4,096\n",
      "          Conv2d-285           [-1, 64, 16, 16]           4,096\n",
      "     BatchNorm2d-286           [-1, 64, 16, 16]             128\n",
      "     BatchNorm2d-287           [-1, 64, 16, 16]             128\n",
      "            ReLU-288           [-1, 64, 16, 16]               0\n",
      "            ReLU-289           [-1, 64, 16, 16]               0\n",
      "      BasicBlock-290           [-1, 64, 16, 16]               0\n",
      "      BasicBlock-291           [-1, 64, 16, 16]               0\n",
      "          Conv2d-292           [-1, 64, 16, 16]          36,864\n",
      "          Conv2d-293           [-1, 64, 16, 16]          36,864\n",
      "     BatchNorm2d-294           [-1, 64, 16, 16]             128\n",
      "     BatchNorm2d-295           [-1, 64, 16, 16]             128\n",
      "            ReLU-296           [-1, 64, 16, 16]               0\n",
      "            ReLU-297           [-1, 64, 16, 16]               0\n",
      "          Conv2d-298           [-1, 64, 16, 16]          36,864\n",
      "          Conv2d-299           [-1, 64, 16, 16]          36,864\n",
      "     BatchNorm2d-300           [-1, 64, 16, 16]             128\n",
      "     BatchNorm2d-301           [-1, 64, 16, 16]             128\n",
      "            ReLU-302           [-1, 64, 16, 16]               0\n",
      "            ReLU-303           [-1, 64, 16, 16]               0\n",
      "      BasicBlock-304           [-1, 64, 16, 16]               0\n",
      "      BasicBlock-305           [-1, 64, 16, 16]               0\n",
      "          Conv2d-306           [-1, 64, 16, 16]          36,864\n",
      "          Conv2d-307           [-1, 64, 16, 16]          36,864\n",
      "     BatchNorm2d-308           [-1, 64, 16, 16]             128\n",
      "     BatchNorm2d-309           [-1, 64, 16, 16]             128\n",
      "            ReLU-310           [-1, 64, 16, 16]               0\n",
      "            ReLU-311           [-1, 64, 16, 16]               0\n",
      "          Conv2d-312           [-1, 64, 16, 16]          36,864\n",
      "          Conv2d-313           [-1, 64, 16, 16]          36,864\n",
      "     BatchNorm2d-314           [-1, 64, 16, 16]             128\n",
      "     BatchNorm2d-315           [-1, 64, 16, 16]             128\n",
      "            ReLU-316           [-1, 64, 16, 16]               0\n",
      "            ReLU-317           [-1, 64, 16, 16]               0\n",
      "      BasicBlock-318           [-1, 64, 16, 16]               0\n",
      "      BasicBlock-319           [-1, 64, 16, 16]               0\n",
      "          Conv2d-320             [-1, 64, 8, 8]          36,864\n",
      "          Conv2d-321             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-322             [-1, 64, 8, 8]             128\n",
      "     BatchNorm2d-323             [-1, 64, 8, 8]             128\n",
      "            ReLU-324             [-1, 64, 8, 8]               0\n",
      "            ReLU-325             [-1, 64, 8, 8]               0\n",
      "          Conv2d-326             [-1, 64, 8, 8]          36,864\n",
      "          Conv2d-327             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-328             [-1, 64, 8, 8]             128\n",
      "     BatchNorm2d-329             [-1, 64, 8, 8]             128\n",
      "          Conv2d-330             [-1, 64, 8, 8]           4,096\n",
      "          Conv2d-331             [-1, 64, 8, 8]           4,096\n",
      "     BatchNorm2d-332             [-1, 64, 8, 8]             128\n",
      "     BatchNorm2d-333             [-1, 64, 8, 8]             128\n",
      "            ReLU-334             [-1, 64, 8, 8]               0\n",
      "            ReLU-335             [-1, 64, 8, 8]               0\n",
      "      BasicBlock-336             [-1, 64, 8, 8]               0\n",
      "      BasicBlock-337             [-1, 64, 8, 8]               0\n",
      "          Conv2d-338             [-1, 64, 8, 8]          36,864\n",
      "          Conv2d-339             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-340             [-1, 64, 8, 8]             128\n",
      "     BatchNorm2d-341             [-1, 64, 8, 8]             128\n",
      "            ReLU-342             [-1, 64, 8, 8]               0\n",
      "            ReLU-343             [-1, 64, 8, 8]               0\n",
      "          Conv2d-344             [-1, 64, 8, 8]          36,864\n",
      "          Conv2d-345             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-346             [-1, 64, 8, 8]             128\n",
      "     BatchNorm2d-347             [-1, 64, 8, 8]             128\n",
      "            ReLU-348             [-1, 64, 8, 8]               0\n",
      "            ReLU-349             [-1, 64, 8, 8]               0\n",
      "      BasicBlock-350             [-1, 64, 8, 8]               0\n",
      "      BasicBlock-351             [-1, 64, 8, 8]               0\n",
      "          Conv2d-352             [-1, 64, 8, 8]          36,864\n",
      "          Conv2d-353             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-354             [-1, 64, 8, 8]             128\n",
      "     BatchNorm2d-355             [-1, 64, 8, 8]             128\n",
      "            ReLU-356             [-1, 64, 8, 8]               0\n",
      "            ReLU-357             [-1, 64, 8, 8]               0\n",
      "          Conv2d-358             [-1, 64, 8, 8]          36,864\n",
      "          Conv2d-359             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-360             [-1, 64, 8, 8]             128\n",
      "     BatchNorm2d-361             [-1, 64, 8, 8]             128\n",
      "            ReLU-362             [-1, 64, 8, 8]               0\n",
      "            ReLU-363             [-1, 64, 8, 8]               0\n",
      "      BasicBlock-364             [-1, 64, 8, 8]               0\n",
      "      BasicBlock-365             [-1, 64, 8, 8]               0\n",
      "          Conv2d-366             [-1, 64, 8, 8]          36,864\n",
      "          Conv2d-367             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-368             [-1, 64, 8, 8]             128\n",
      "     BatchNorm2d-369             [-1, 64, 8, 8]             128\n",
      "            ReLU-370             [-1, 64, 8, 8]               0\n",
      "            ReLU-371             [-1, 64, 8, 8]               0\n",
      "          Conv2d-372             [-1, 64, 8, 8]          36,864\n",
      "          Conv2d-373             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-374             [-1, 64, 8, 8]             128\n",
      "     BatchNorm2d-375             [-1, 64, 8, 8]             128\n",
      "            ReLU-376             [-1, 64, 8, 8]               0\n",
      "            ReLU-377             [-1, 64, 8, 8]               0\n",
      "      BasicBlock-378             [-1, 64, 8, 8]               0\n",
      "      BasicBlock-379             [-1, 64, 8, 8]               0\n",
      "          Linear-380                    [-1, 2]           8,194\n",
      "          Linear-381                    [-1, 2]           8,194\n",
      "================================================================\n",
      "Total params: 43,878,088\n",
      "Trainable params: 43,878,088\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 87.53\n",
      "Params size (MB): 167.38\n",
      "Estimated Total Size (MB): 255.10\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = feature_sieve(2, False).to(device)\n",
    "summary(model, (3, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c96d6d-c8c5-4694-9cf8-445f7309a11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                        | 7/10 [1:02:09<26:35, 531.98s/it]"
     ]
    }
   ],
   "source": [
    "model = feature_sieve(2, False).to(device)\n",
    "model, fs_train_losses, fs_train_accs, fs_val_losses, fs_val_accs = train_fs(model, train_dataloader, val_dataloader, epochs = 10, verbose = False)\n",
    "fs_test_loss, fs_test_acc = eval_fsmodel(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff5ccc2-1f45-4aab-9eb3-80306f91ab13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_loss_curves(fs_train_losses, fs_val_losses, fs_test_loss, epochs = 10, model_name = \"Feature Sieve Loss Curves\")\n",
    "plot_loss_curves(fs_train_accs, fs_val_accs, fs_test_acc, epochs = 10, model_name = \"Feature Sieve Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6ce224-310a-4871-b7ab-78cc34797f2a",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d630ec91-c0c3-4442-acff-e98c64baa5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:20<00:00, 560.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.14336559176445007 Test Accuracy :0.9413637373213889\n",
      "Test Loss: 1.1971088647842407 Test Accuracy :0.4601063829787234\n",
      "Test Loss: 0.4164236783981323 Test Accuracy :0.8227714033539276\n",
      "Test Loss: 0.043938905000686646 Test Accuracy :0.9885050517272672\n",
      "Test Loss: 0.1259642243385315 Test Accuracy :0.9461868419586652\n",
      "Mean group accuracy: 0.804392420004646\n",
      "Mean group loss: 0.445858895778656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.804392420004646, 0.4458589)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hyperparameter tuning based on architecture\n",
    "\n",
    "## different aux layer connections\n",
    "### 1) To first block: 0.9394634880679154\n",
    "### 2) To second block: 0.9151551047604946\n",
    "\n",
    "## different capacity of Aux layer\n",
    "### 1) 64, 64 : 0.9384\n",
    "### 2) 128, 128: 0.939\n",
    "### 3) 64, 128: 0.9430418795192617\n",
    "### 4) 128, 256: :0.9390192739567138\n",
    "### 5) 64, 128, 128: 0.9351694183263\n",
    "### 6) 64, 64, 128: \n",
    "### 7) 64, 2 fcs: 0.92\n",
    "### 8) 64, 64, 64: \n",
    "model = feature_sieve(2, False).to(device)\n",
    "model, fs_train_losses, fs_train_accs, fs_val_losses, fs_val_accs = train_fs(model, train_dataloader, val_dataloader, epochs = 1, verbose = False)\n",
    "fs_test_loss, fs_test_acc = eval_fsmodel(model, test_dataloader)\n",
    "mean_group(model, groups, type='fs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f01d670-aa68-4e57-8847-c3fb834db0b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [11:07<00:00, 667.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1698313057422638 Test Accuracy :0.9339601688013622\n",
      "Test Loss: 1.1746660470962524 Test Accuracy :0.35097493036211697\n",
      "Test Loss: 0.5441424250602722 Test Accuracy :0.7480861669930567\n",
      "Test Loss: 0.0791403204202652 Test Accuracy :0.9811571445826791\n",
      "Test Loss: 0.11581231653690338 Test Accuracy :0.9594707288597321\n",
      "Mean group accuracy: 0.7599222426993962\n",
      "Mean group loss: 0.4784402549266815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:52<00:00, 592.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1575603187084198 Test Accuracy :0.9368969176476395\n",
      "Test Loss: 1.764522910118103 Test Accuracy :0.20055710306406685\n",
      "Test Loss: 0.716614842414856 Test Accuracy :0.6868435107708741\n",
      "Test Loss: 0.03241842985153198 Test Accuracy :0.9948665297741273\n",
      "Test Loss: 0.06531023234128952 Test Accuracy :0.9755378884750098\n",
      "Mean group accuracy: 0.7144512580210195\n",
      "Mean group loss: 0.6447166204452515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:48<00:00, 588.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.15700103342533112 Test Accuracy :0.9340095259248291\n",
      "Test Loss: 1.5517865419387817 Test Accuracy :0.3370473537604457\n",
      "Test Loss: 0.4533149003982544 Test Accuracy :0.8102189781021898\n",
      "Test Loss: 0.040253229439258575 Test Accuracy :0.9897934533156179\n",
      "Test Loss: 0.14442665874958038 Test Accuracy :0.9336743203424696\n",
      "Mean group accuracy: 0.7676835263801807\n",
      "Mean group loss: 0.5474452972412109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [11:01<00:00, 661.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.19825208187103271 Test Accuracy :0.9087140001480714\n",
      "Test Loss: 2.0077927112579346 Test Accuracy :0.1309192200557103\n",
      "Test Loss: 1.1267412900924683 Test Accuracy :0.4299448103970091\n",
      "Test Loss: 0.018203552812337875 Test Accuracy :0.9983089745138302\n",
      "Test Loss: 0.03885316103696823 Test Accuracy :0.9922721965864235\n",
      "Mean group accuracy: 0.6378613003882433\n",
      "Mean group loss: 0.7978976368904114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:45<00:00, 585.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.13213969767093658 Test Accuracy :0.9465462352854076\n",
      "Test Loss: 1.5301004648208618 Test Accuracy :0.37604456824512533\n",
      "Test Loss: 0.48555824160575867 Test Accuracy :0.797578778707495\n",
      "Test Loss: 0.031048543751239777 Test Accuracy :0.9910617224302452\n",
      "Test Loss: 0.08672534674406052 Test Accuracy :0.9637515983766053\n",
      "Mean group accuracy: 0.7821091669398678\n",
      "Mean group loss: 0.533358097076416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:37<00:00, 577.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.163121297955513 Test Accuracy :0.9276671355593396\n",
      "Test Loss: 1.5047574043273926 Test Accuracy :0.22562674094707522\n",
      "Test Loss: 0.7481865286827087 Test Accuracy :0.6056613850810041\n",
      "Test Loss: 0.03201163187623024 Test Accuracy :0.9966783427950235\n",
      "Test Loss: 0.07459206134080887 Test Accuracy :0.9774281425473953\n",
      "Mean group accuracy: 0.7013486528426246\n",
      "Mean group loss: 0.5898869633674622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [10:46<00:00, 646.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.16511249542236328 Test Accuracy :0.9312455270106859\n",
      "Test Loss: 1.3234869241714478 Test Accuracy :0.41225626740947074\n",
      "Test Loss: 0.44504740834236145 Test Accuracy :0.8260637350899056\n",
      "Test Loss: 0.08427189290523529 Test Accuracy :0.9670250030196884\n",
      "Test Loss: 0.1277719885110855 Test Accuracy :0.9426808250403069\n",
      "Mean group accuracy: 0.7870064576398429\n",
      "Mean group loss: 0.4951445460319519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:42<00:00, 582.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1350981891155243 Test Accuracy :0.9454357000074036\n",
      "Test Loss: 1.2267168760299683 Test Accuracy :0.467966573816156\n",
      "Test Loss: 0.46199342608451843 Test Accuracy :0.8118212568987003\n",
      "Test Loss: 0.042480140924453735 Test Accuracy :0.9878004589926319\n",
      "Test Loss: 0.0962134301662445 Test Accuracy :0.9605270473119475\n",
      "Mean group accuracy: 0.8070288342548589\n",
      "Mean group loss: 0.45685097575187683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [08:50<00:00, 530.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.15875907242298126 Test Accuracy :0.9358357394931024\n",
      "Test Loss: 2.282233476638794 Test Accuracy :0.1671309192200557\n",
      "Test Loss: 0.7636476755142212 Test Accuracy :0.6644116076197258\n",
      "Test Loss: 0.012468041852116585 Test Accuracy :0.9978258243749245\n",
      "Test Loss: 0.060823630541563034 Test Accuracy :0.9778173125034747\n",
      "Mean group accuracy: 0.7017964159295452\n",
      "Mean group loss: 0.7797932624816895\n",
      "Best forget lr: 0.001\n",
      "Best forget iter: 50\n"
     ]
    }
   ],
   "source": [
    "forget_iters = [2, 50, 100]\n",
    "forget_lrs = [1e-5, 1e-4, 1e-3]\n",
    "groups = [male_blond_dataloader, female_blond_dataloader, male_non_blond_dataloader, female_non_blond_dataloader]\n",
    "\n",
    "test_accs = np.zeros((len(forget_lrs), len(forget_iters)))\n",
    "\n",
    "for i in range(len(forget_lrs)):\n",
    "    for j in range(len(forget_iters)):\n",
    "        \n",
    "            model = feature_sieve(2, False).to(device)\n",
    "            model, fs_train_losses, fs_train_accs, fs_val_losses, fs_val_accs = train_fs(model, train_dataloader, val_dataloader, epochs = 1, lrs = [1e-4, 1e-4, forget_lrs[i]], forget_iters = forget_iters[j], verbose= False)\n",
    "            fs_test_loss, fs_test_accs = eval_fsmodel(model, test_dataloader)\n",
    "    \n",
    "            test_accs[i,j] = mean_group(model, groups)[0]\n",
    "\n",
    "best_forget_lr, best_forget_iter = np.unravel_index(np.argmax(test_accs), test_accs.shape)\n",
    "print(f\"Best forget lr: {forget_lrs[best_forget_lr]}\")\n",
    "print(f\"Best forget iter: {forget_iters[best_forget_iter]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b43205b-3b7f-4466-8b9d-5ef3786ada4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "forget_iters = [20, 50, 100]\n",
    "forget_lrs = [1e-5, 1e-3, 1e-2]\n",
    "lrs = [1e-5, 1e-4, 1e-3]\n",
    "\n",
    "best_lr = 1\n",
    "best_forget_lr = 0\n",
    "best_forget_iter = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d227711-b77d-41ef-99e2-49823e7192e9",
   "metadata": {},
   "source": [
    "### Finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fd87f4a-6ba6-4db4-80df-e2324dca5ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [1:20:59<00:00, 485.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.11016113311052322 Test Accuracy :0.9565163742257101\n"
     ]
    }
   ],
   "source": [
    "model = feature_sieve(2, False).to(device)\n",
    "model, fs_train_lossses, fs_train_accs, fs_val_losses, fs_val_accs = train_fs(model, train_dataloader, val_dataloader, epochs = 10, lrs = [lrs[best_lr], lrs[best_lr], forget_lrs[best_forget_lr]], forget_iters = forget_iters[best_forget_iter], verbose = False)\n",
    "fs_test_loss, fs_test_acc = eval_fsmodel(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73d199c3-1a62-4873-93b9-d866a5b3eee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.3099322319030762 Test Accuracy :0.4456824512534819\n",
      "Test Loss: 0.331999808549881 Test Accuracy :0.881075307103436\n",
      "Test Loss: 0.02497711032629013 Test Accuracy :0.9922695977775093\n",
      "Test Loss: 0.09595800936222076 Test Accuracy :0.9561349863790516\n",
      "Mean group accuracy: 0.8187905856283697\n",
      "Mean group loss: 0.44071677327156067\n"
     ]
    }
   ],
   "source": [
    "# 75 1e-5: 81.308\n",
    "group_wise_acc_fs = []\n",
    "group_wise_loss_fs = []\n",
    "groups = [male_blond_dataloader, female_blond_dataloader, male_non_blond_dataloader, female_non_blond_dataloader]\n",
    "\n",
    "for group in range(len(groups)):\n",
    "    loss, acc = eval_fsmodel(model, groups[group])\n",
    "    group_wise_acc_fs.append(acc)\n",
    "    group_wise_loss_fs.append(loss)\n",
    "\n",
    "mean_group_acc = np.mean(group_wise_acc_fs)\n",
    "mean_group_loss = np.mean(group_wise_loss_fs)\n",
    "\n",
    "print(f\"Mean group accuracy: {mean_group_acc}\")\n",
    "print(f\"Mean group loss: {mean_group_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1100f860-4600-4f20-8ceb-242d6a61b7f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_curves(fs_train_lossses, fs_val_losses, fs_test_loss, epochs = 10, model_name = \"Feature Sieve Loss Curves\")\n",
    "plot_loss_curves(fs_train_accs, fs_val_accs, fs_test_acc, epochs = 10, model_name = \"Feature Sieve Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8290c6e-28b8-4e7d-88fb-f18278698597",
   "metadata": {},
   "source": [
    "## Comparison plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da97b0c-dfb9-4b85-91f2-0f29ffe70645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Comparisons\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
    "fig, ax = plt.subplots(2, 3)\n",
    "fig.suptitle(\"CNN vs Feature Sieve (Space Invaders)\")\n",
    "\n",
    "# Training Loss\n",
    "ax[0,0].plot(range(len(train_losses)), train_losses, color = \"blue\", label = \"CNN\")\n",
    "ax[0,0].plot(range(len(fs_train_lossses)), fs_train_lossses,color = \"red\", label= \"Feature Sieve\")\n",
    "ax[0,0].set_xlabel(\"Epochs\")\n",
    "ax[0,0].set_ylabel(\"Loss\")\n",
    "ax[0,0].set_title(\"Training Loss\")\n",
    "ax[0,0].legend()\n",
    "\n",
    "#Validation Loss\n",
    "ax[0,1].plot(range(len(val_losses)), val_losses, color = \"blue\", label = \"CNN\")\n",
    "ax[0,1].plot(range(len(fs_val_losses)), fs_val_losses, color = \"red\", label= \"Feature Sieve\")\n",
    "ax[0,1].set_xlabel(\"Epochs\")\n",
    "ax[0,1].set_ylabel(\"Loss\")\n",
    "ax[0,1].set_title(\"Validation Loss\")\n",
    "ax[0,1].legend()\n",
    "\n",
    "#Training  Accuracy\n",
    "ax[1,0].plot(range(len(train_accs)), train_accs, color = \"blue\", label = \"CNN\")\n",
    "ax[1,0].plot(range(len(fs_train_accs)), fs_train_accs,color = \"red\", label= \"Feature Sieve\")\n",
    "ax[1,0].set_xlabel(\"Epochs\")\n",
    "ax[1,0].set_ylabel(\"Loss\")\n",
    "ax[1,0].set_title(\"Training Accuracy\")\n",
    "ax[1,0].legend()\n",
    "\n",
    "#Validation Accuracy\n",
    "ax[1,1].plot(range(len(val_losses)), val_accs, color = \"blue\", label = \"CNN\")\n",
    "ax[1,1].plot(range(len(val_losses)), fs_val_accs, color = \"red\", label= \"Feature Sieve\")\n",
    "ax[1,1].set_xlabel(\"Epochs\")\n",
    "ax[1,1].set_ylabel(\"Loss\")\n",
    "ax[1,1].set_title(\"Validation Accuracy\")\n",
    "ax[1,1].legend()\n",
    "\n",
    "#Test Loss:\n",
    "models = [\"CNN\", \"Feature Sieve\"]\n",
    "test_losses = [test_loss, fs_test_loss]\n",
    "ax[0,2].bar(models, test_losses, width = 0.4)\n",
    "ax[0,2].set_xlabel(\"Models\")\n",
    "ax[0,2].set_ylabel(\"Test Loss\")\n",
    "ax[0,2].set_title(\"Test Loss\")\n",
    "# ax[0,2].legend()\n",
    "\n",
    "# Test accuracy\n",
    "test_accs = [test_acc, fs_test_acc]\n",
    "ax[1,2].bar(models, test_accs, width = 0.4)\n",
    "ax[1,2].set_xlabel(\"Models\")\n",
    "ax[1,2].set_ylabel(\"Test Accuracy\")\n",
    "ax[1,2].set_title(\"Test Accuracy\")\n",
    "# ax[1,2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"./data/cnn_vs_fs_celeba.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83de9d9b-d90d-440b-b8c1-335d7551458a",
   "metadata": {},
   "source": [
    "## Group wise comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599a93ac-2723-4ca0-ab4f-c150b886449c",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_accuracies = {\n",
    "    'cnn': group_wise_acc,\n",
    "    'Feature Sieve': group_wise_acc_fs\n",
    "}\n",
    "\n",
    "groups = ['male blond', 'female blond', 'male non blond', 'female non blond']\n",
    "\n",
    "x = np.arange(len(group_wise_acc))\n",
    "width = 0.2\n",
    "multiplier = 0\n",
    "\n",
    "fig, ax = plt.subplots(layout=\"constrained\")\n",
    "\n",
    "for model_type, group_acc in group_accuracies.items():\n",
    "    offset = width*multiplier\n",
    "    rects = ax.bar(x + offset, group_acc, width, label=model_type)\n",
    "    ax.bar_label(rects, padding=3)\n",
    "    multiplier += 1\n",
    "\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_title(\"Groups\")\n",
    "ax.set_xticks(x+ width, groups)\n",
    "ax.legend(loc=\"upper left\")\n",
    "\n",
    "plt.savefig(\"./group_accs_comp.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68018c43-8c61-4fc9-ba59-712a003618e7",
   "metadata": {},
   "source": [
    "# pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "412d6cb5-f101-4f04-b83e-479747726de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet34(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Resnet34, self).__init__()\n",
    "        resnet = models.resnet34(pretrained = True)\n",
    "        self.features = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0a6a3bb-2fc4-49a4-88a0-85e13fdfb068",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/storage0/be20b032/miniconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/scratch/storage0/be20b032/miniconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 64, 64]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 64, 64]             128\n",
      "              ReLU-3           [-1, 64, 64, 64]               0\n",
      "         MaxPool2d-4           [-1, 64, 32, 32]               0\n",
      "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
      "              ReLU-7           [-1, 64, 32, 32]               0\n",
      "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
      "             ReLU-10           [-1, 64, 32, 32]               0\n",
      "       BasicBlock-11           [-1, 64, 32, 32]               0\n",
      "           Conv2d-12           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 32, 32]             128\n",
      "             ReLU-14           [-1, 64, 32, 32]               0\n",
      "           Conv2d-15           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 32, 32]             128\n",
      "             ReLU-17           [-1, 64, 32, 32]               0\n",
      "       BasicBlock-18           [-1, 64, 32, 32]               0\n",
      "           Conv2d-19           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-20           [-1, 64, 32, 32]             128\n",
      "             ReLU-21           [-1, 64, 32, 32]               0\n",
      "           Conv2d-22           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-23           [-1, 64, 32, 32]             128\n",
      "             ReLU-24           [-1, 64, 32, 32]               0\n",
      "       BasicBlock-25           [-1, 64, 32, 32]               0\n",
      "           Conv2d-26          [-1, 128, 16, 16]          73,728\n",
      "      BatchNorm2d-27          [-1, 128, 16, 16]             256\n",
      "             ReLU-28          [-1, 128, 16, 16]               0\n",
      "           Conv2d-29          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-30          [-1, 128, 16, 16]             256\n",
      "           Conv2d-31          [-1, 128, 16, 16]           8,192\n",
      "      BatchNorm2d-32          [-1, 128, 16, 16]             256\n",
      "             ReLU-33          [-1, 128, 16, 16]               0\n",
      "       BasicBlock-34          [-1, 128, 16, 16]               0\n",
      "           Conv2d-35          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-36          [-1, 128, 16, 16]             256\n",
      "             ReLU-37          [-1, 128, 16, 16]               0\n",
      "           Conv2d-38          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-39          [-1, 128, 16, 16]             256\n",
      "             ReLU-40          [-1, 128, 16, 16]               0\n",
      "       BasicBlock-41          [-1, 128, 16, 16]               0\n",
      "           Conv2d-42          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-43          [-1, 128, 16, 16]             256\n",
      "             ReLU-44          [-1, 128, 16, 16]               0\n",
      "           Conv2d-45          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-46          [-1, 128, 16, 16]             256\n",
      "             ReLU-47          [-1, 128, 16, 16]               0\n",
      "       BasicBlock-48          [-1, 128, 16, 16]               0\n",
      "           Conv2d-49          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-50          [-1, 128, 16, 16]             256\n",
      "             ReLU-51          [-1, 128, 16, 16]               0\n",
      "           Conv2d-52          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 16, 16]             256\n",
      "             ReLU-54          [-1, 128, 16, 16]               0\n",
      "       BasicBlock-55          [-1, 128, 16, 16]               0\n",
      "           Conv2d-56            [-1, 256, 8, 8]         294,912\n",
      "      BatchNorm2d-57            [-1, 256, 8, 8]             512\n",
      "             ReLU-58            [-1, 256, 8, 8]               0\n",
      "           Conv2d-59            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-60            [-1, 256, 8, 8]             512\n",
      "           Conv2d-61            [-1, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-62            [-1, 256, 8, 8]             512\n",
      "             ReLU-63            [-1, 256, 8, 8]               0\n",
      "       BasicBlock-64            [-1, 256, 8, 8]               0\n",
      "           Conv2d-65            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-66            [-1, 256, 8, 8]             512\n",
      "             ReLU-67            [-1, 256, 8, 8]               0\n",
      "           Conv2d-68            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-69            [-1, 256, 8, 8]             512\n",
      "             ReLU-70            [-1, 256, 8, 8]               0\n",
      "       BasicBlock-71            [-1, 256, 8, 8]               0\n",
      "           Conv2d-72            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-73            [-1, 256, 8, 8]             512\n",
      "             ReLU-74            [-1, 256, 8, 8]               0\n",
      "           Conv2d-75            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-76            [-1, 256, 8, 8]             512\n",
      "             ReLU-77            [-1, 256, 8, 8]               0\n",
      "       BasicBlock-78            [-1, 256, 8, 8]               0\n",
      "           Conv2d-79            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-80            [-1, 256, 8, 8]             512\n",
      "             ReLU-81            [-1, 256, 8, 8]               0\n",
      "           Conv2d-82            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-83            [-1, 256, 8, 8]             512\n",
      "             ReLU-84            [-1, 256, 8, 8]               0\n",
      "       BasicBlock-85            [-1, 256, 8, 8]               0\n",
      "           Conv2d-86            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-87            [-1, 256, 8, 8]             512\n",
      "             ReLU-88            [-1, 256, 8, 8]               0\n",
      "           Conv2d-89            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-90            [-1, 256, 8, 8]             512\n",
      "             ReLU-91            [-1, 256, 8, 8]               0\n",
      "       BasicBlock-92            [-1, 256, 8, 8]               0\n",
      "           Conv2d-93            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-94            [-1, 256, 8, 8]             512\n",
      "             ReLU-95            [-1, 256, 8, 8]               0\n",
      "           Conv2d-96            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-97            [-1, 256, 8, 8]             512\n",
      "             ReLU-98            [-1, 256, 8, 8]               0\n",
      "       BasicBlock-99            [-1, 256, 8, 8]               0\n",
      "          Conv2d-100            [-1, 512, 4, 4]       1,179,648\n",
      "     BatchNorm2d-101            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-102            [-1, 512, 4, 4]               0\n",
      "          Conv2d-103            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-104            [-1, 512, 4, 4]           1,024\n",
      "          Conv2d-105            [-1, 512, 4, 4]         131,072\n",
      "     BatchNorm2d-106            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-107            [-1, 512, 4, 4]               0\n",
      "      BasicBlock-108            [-1, 512, 4, 4]               0\n",
      "          Conv2d-109            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-110            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-111            [-1, 512, 4, 4]               0\n",
      "          Conv2d-112            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-113            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-114            [-1, 512, 4, 4]               0\n",
      "      BasicBlock-115            [-1, 512, 4, 4]               0\n",
      "          Conv2d-116            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-117            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-118            [-1, 512, 4, 4]               0\n",
      "          Conv2d-119            [-1, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-120            [-1, 512, 4, 4]           1,024\n",
      "            ReLU-121            [-1, 512, 4, 4]               0\n",
      "      BasicBlock-122            [-1, 512, 4, 4]               0\n",
      "AdaptiveAvgPool2d-123            [-1, 512, 1, 1]               0\n",
      "          Linear-124                    [-1, 2]           1,026\n",
      "================================================================\n",
      "Total params: 21,285,698\n",
      "Trainable params: 21,285,698\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 31.44\n",
      "Params size (MB): 81.20\n",
      "Estimated Total Size (MB): 112.83\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "resnet_model = Resnet34(2).to(device)\n",
    "summary(resnet_model, (3, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "859f146a-9b69-4ebb-82e6-b995b0bd2d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [05:31<00:00, 331.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1150081604719162 Accuracy:0.9535549468176995\n",
      "Test Loss: 1.5156474113464355 Accuracy:0.36363636363636365\n",
      "Test Loss: 0.36022359132766724 Accuracy:0.8568137515505937\n",
      "Test Loss: 0.020942971110343933 Accuracy:0.9963144220892998\n",
      "Test Loss: 0.09621182829141617 Accuracy:0.9569431292820142\n",
      "Mean group accuracy: 0.7934269166395679\n",
      "Mean group loss: 0.4982564151287079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7934269166395679, 0.49825642)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Resnet34(2).to(device)\n",
    "model, train_losses, train_accs, val_losses, val_accs = train_cnn(model, train_dataloader, val_dataloader, epochs = 1, verbose = False)\n",
    "test_loss, test_acc = eval_cnn(model, test_dataloader)\n",
    "mean_group(model, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b42d4c48-3864-4a22-8267-226065bbf58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiFer(nn.Module):\n",
    "    def __init__(self, block, num_classes, aux_pos = 1, aux_kernels = [128, 64], layers = [3, 4]):\n",
    "        super(SiFer, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.aux_pos = aux_pos + 4\n",
    "        # main network\n",
    "        network = models.resnet34(pretrained = True)\n",
    "        self.layers = nn.ModuleList(list(network.children())[:-1])\n",
    "        self.layers.append(nn.Linear(512, num_classes))\n",
    "\n",
    "        # Auxiliary Network\n",
    "        self.aux_layers = nn.ModuleList([])\n",
    "        \n",
    "        self.inplanes = 128\n",
    "        for kernel_id in range(len(aux_kernels)):\n",
    "            self.aux_layers.append(self.__make_layer(block, aux_kernels[kernel_id], layers[kernel_id], stride = 2))\n",
    "            \n",
    "        self.aux_layers.append(nn.AvgPool2d(7, stride=1, padding=2))\n",
    "        self.aux_layers.append(nn.Linear(512, num_classes))\n",
    "\n",
    "        # parameters dict\n",
    "        self.params = nn.ModuleDict({\n",
    "            \"main\" : self.layers,\n",
    "            \"aux\"  : self.aux_layers,\n",
    "            'forget': self.layers[:self.aux_pos]\n",
    "        })\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # forward for the main network\n",
    "        outputs_main = []\n",
    "        \n",
    "        for layer in self.layers[:-1]:\n",
    "            x = layer(x)\n",
    "            outputs_main.append(x)\n",
    "\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.layers[-1](x)\n",
    "        outputs_main.append(x)\n",
    "\n",
    "        # forward for the aux network\n",
    "        aux = outputs_main[self.aux_pos]\n",
    "        for aux_layer in self.aux_layers[:-1]:\n",
    "            aux = aux_layer(aux)\n",
    "\n",
    "        aux = aux.view(aux.shape[0], -1)\n",
    "        aux = self.aux_layers[-1](aux)\n",
    "        return x, aux\n",
    "\n",
    "    def __make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1f1b0e07-ad96-48a7-a066-98efd360333b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [11:43<00:00, 703.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.14568211138248444 Test Accuracy :0.9397102736852496\n",
      "Test Loss: 0.9497866034507751 Test Accuracy :0.6382978723404256\n",
      "Test Loss: 0.2329520583152771 Test Accuracy :0.9133274492497794\n",
      "Test Loss: 0.05408108979463577 Test Accuracy :0.9801560892975981\n",
      "Test Loss: 0.1872778832912445 Test Accuracy :0.9166063171968135\n",
      "Mean group accuracy: 0.8620969320211541\n",
      "Mean group loss: 0.3560244143009186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8620969320211541, 0.3560244)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =  SiFer(BasicBlock, 2, aux_kernels = [128, 128], layers = [4, 5]).to(device)\n",
    "model, train_sifer_losses, train_sifer_accs, val_sifer_losses, val_sifer_accs = train_fs(model, train_dataloader, val_dataloader, forget_iters = 10, lrs = [1e-4, 1e-4, 1e-4], epochs = 1, verbose = False)\n",
    "test_loss, test_acc = eval_fsmodel(model, test_dataloader)\n",
    "mean_group(model, groups, type = 'fs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1865f2fb-43d3-427b-9fb9-34dc8a9402a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/storage0/be20b032/miniconda3/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [11:22<00:00, 682.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.13324549794197083 Test Accuracy :0.9462007354211397\n",
      "Test Loss: 1.4875208139419556 Test Accuracy :0.2956989247311828\n",
      "Test Loss: 0.38266441226005554 Test Accuracy :0.8386866523911491\n",
      "Test Loss: 0.03626590967178345 Test Accuracy :0.9921511803417256\n",
      "Test Loss: 0.11645053327083588 Test Accuracy :0.9512290067845623\n",
      "Mean group accuracy: 0.769441441062155\n",
      "Mean group loss: 0.5057254433631897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [10:34<00:00, 634.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1394372284412384 Test Accuracy :0.9425483082845931\n",
      "Test Loss: 1.355662226676941 Test Accuracy :0.478494623655914\n",
      "Test Loss: 0.2976400554180145 Test Accuracy :0.8888294075660242\n",
      "Test Loss: 0.04159597307443619 Test Accuracy :0.9871400108675964\n",
      "Test Loss: 0.15435107052326202 Test Accuracy :0.9302635969302636\n",
      "Mean group accuracy: 0.8211819097549495\n",
      "Mean group loss: 0.46231234073638916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [10:15<00:00, 615.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.13873571157455444 Test Accuracy :0.9458552355568718\n",
      "Test Loss: 2.1122255325317383 Test Accuracy :0.22311827956989247\n",
      "Test Loss: 0.6402254104614258 Test Accuracy :0.7425053533190579\n",
      "Test Loss: 0.013825788162648678 Test Accuracy :0.9973434764233533\n",
      "Test Loss: 0.056406617164611816 Test Accuracy :0.9776999221443666\n",
      "Mean group accuracy: 0.7351667578641675\n",
      "Mean group loss: 0.7056708335876465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [11:25<00:00, 685.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1327960193157196 Test Accuracy :0.9472619135756768\n",
      "Test Loss: 1.679449439048767 Test Accuracy :0.2446236559139785\n",
      "Test Loss: 0.5142436027526855 Test Accuracy :0.7855103497501784\n",
      "Test Loss: 0.027545733377337456 Test Accuracy :0.994445450703375\n",
      "Test Loss: 0.07968510687351227 Test Accuracy :0.9686353019686353\n",
      "Mean group accuracy: 0.7483036895840418\n",
      "Mean group loss: 0.5752310156822205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [10:10<00:00, 610.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.12130971997976303 Test Accuracy :0.950840305027023\n",
      "Test Loss: 1.2907079458236694 Test Accuracy :0.43548387096774194\n",
      "Test Loss: 0.2578207552433014 Test Accuracy :0.9029264810849393\n",
      "Test Loss: 0.03014342673122883 Test Accuracy :0.9907625430175693\n",
      "Test Loss: 0.13764218986034393 Test Accuracy :0.9382159937715493\n",
      "Mean group accuracy: 0.8168472222104499\n",
      "Mean group loss: 0.4290785491466522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:51<00:00, 591.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.16637958586215973 Test Accuracy :0.9338367759926951\n",
      "Test Loss: 1.7970327138900757 Test Accuracy :0.33064516129032256\n",
      "Test Loss: 0.6173924207687378 Test Accuracy :0.7403640256959315\n",
      "Test Loss: 0.06047535315155983 Test Accuracy :0.980317575318481\n",
      "Test Loss: 0.09032683074474335 Test Accuracy :0.9634634634634635\n",
      "Mean group accuracy: 0.7536975564420497\n",
      "Mean group loss: 0.6413068175315857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [11:09<00:00, 669.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.13834871351718903 Test Accuracy :0.9440043434268651\n",
      "Test Loss: 1.71884286403656 Test Accuracy :0.30913978494623656\n",
      "Test Loss: 0.5062057971954346 Test Accuracy :0.7865810135617416\n",
      "Test Loss: 0.026125380769371986 Test Accuracy :0.9933586910583831\n",
      "Test Loss: 0.09233415126800537 Test Accuracy :0.9620175731286842\n",
      "Mean group accuracy: 0.7627742656737615\n",
      "Mean group loss: 0.5858770608901978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:54<00:00, 594.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.12040935456752777 Test Accuracy :0.9509636978356901\n",
      "Test Loss: 1.6925352811813354 Test Accuracy :0.31451612903225806\n",
      "Test Loss: 0.3459051847457886 Test Accuracy :0.8679514632405425\n",
      "Test Loss: 0.02117122709751129 Test Accuracy :0.9938416953450462\n",
      "Test Loss: 0.10935906320810318 Test Accuracy :0.9503392281170059\n",
      "Mean group accuracy: 0.7816621289337131\n",
      "Mean group loss: 0.542242705821991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:49<00:00, 589.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.12624716758728027 Test Accuracy :0.9500505910515535\n",
      "Test Loss: 2.1343185901641846 Test Accuracy :0.21236559139784947\n",
      "Test Loss: 0.492754727602005 Test Accuracy :0.7806923625981442\n",
      "Test Loss: 0.014926813542842865 Test Accuracy :0.996981223208356\n",
      "Test Loss: 0.07273456454277039 Test Accuracy :0.9739183628072517\n",
      "Mean group accuracy: 0.7409893850029003\n",
      "Mean group loss: 0.6786836981773376\n",
      "Best forget lr: 1e-05\n",
      "Best forget iter: 10\n"
     ]
    }
   ],
   "source": [
    "forget_iters = [2, 10, 50, 100]\n",
    "forget_lrs = [1e-5, 1e-4, 1e-3]\n",
    "groups = [male_blond_dataloader, female_blond_dataloader, male_non_blond_dataloader, female_non_blond_dataloader]\n",
    "\n",
    "test_accs = np.zeros((len(forget_lrs), len(forget_iters)))\n",
    "\n",
    "for i in range(len(forget_lrs)):\n",
    "    for j in range(len(forget_iters)):\n",
    "            print(f\"Forget lr: {forget_lrs[i]} Forget iters: {forget_iters[j]}\")\n",
    "            model = SiFer(BasicBlock, 2, aux_kernels = [128, 128], layers = [4, 5]).to(device)\n",
    "            model, fs_train_losses, fs_train_accs, fs_val_losses, fs_val_accs = train_fs(model, train_dataloader, val_dataloader, epochs = 1, lrs = [1e-4, 1e-4, forget_lrs[i]], forget_iters = forget_iters[j], verbose= False)\n",
    "            fs_test_loss, fs_test_accs = eval_fsmodel(model, test_dataloader)\n",
    "    \n",
    "            test_accs[i,j] = mean_group(model, groups, type = 'fs')[0]\n",
    "\n",
    "best_forget_lr, best_forget_iter = np.unravel_index(np.argmax(test_accs), test_accs.shape)\n",
    "print(f\"Best forget lr: {forget_lrs[best_forget_lr]}\")\n",
    "print(f\"Best forget iter: {forget_iters[best_forget_iter]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "316759ce-bb07-430a-8daa-fa1f6d58f519",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [09:07<00:00, 547.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.14257486164569855 Test Accuracy :0.9426963796549938\n",
      "Test Loss: 0.8375502228736877 Test Accuracy :0.6720430107526881\n",
      "Test Loss: 0.18531036376953125 Test Accuracy :0.9305829596412556\n",
      "Test Loss: 0.05652526766061783 Test Accuracy :0.9802046534291631\n",
      "Test Loss: 0.19450326263904572 Test Accuracy :0.9171072923551443\n",
      "Mean group accuracy: 0.8749844790445627\n",
      "Mean group loss: 0.3184722661972046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8749844790445627, 0.31847227)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =  SiFer(BasicBlock, 2, aux_kernels = [64, 128], layers = [3, 4]).to(device)\n",
    "model, train_sifer_losses, train_sifer_accs, val_sifer_losses, val_sifer_accs = train_fs(model, train_dataloader, val_dataloader, forget_iters = 20, lrs = [1e-4, 1e-4, 1e-4], epochs = 1, verbose = False)\n",
    "test_loss, test_acc = eval_fsmodel(model, test_dataloader)\n",
    "mean_group(model, groups, type = 'fs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "884a4fd8-a07e-4c88-9c2b-4be62c666e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [07:52<00:00, 472.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.12100166082382202 Test Accuracy :0.9508156264652896\n",
      "Test Loss: 1.6085113286972046 Test Accuracy :0.29411764705882354\n",
      "Test Loss: 0.42256608605384827 Test Accuracy :0.8178273967747652\n",
      "Test Loss: 0.01822655275464058 Test Accuracy :0.9961331641592653\n",
      "Test Loss: 0.09130536764860153 Test Accuracy :0.9632930429454687\n",
      "Mean group accuracy: 0.7678428127345807\n",
      "Mean group loss: 0.5351523160934448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7678428127345807, 0.5351523)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =  SiFer(BasicBlock, 2, aux_kernels = [64, 128], layers = [3, 4]).to(device)\n",
    "model, train_sifer_losses, train_sifer_accs, val_sifer_losses, val_sifer_accs = train_fs(model, train_dataloader, val_dataloader, forget_iters = 20, lrs = [1e-4, 1e-4, 1e-4], epochs = 1, verbose = False)\n",
    "test_loss, test_acc = eval_fsmodel(model, test_dataloader)\n",
    "mean_group(model, groups, type = 'fs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dd6702-3c1f-4748-bf72-ff4efd8a0379",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
